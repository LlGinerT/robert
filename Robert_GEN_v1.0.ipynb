{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import random\n",
    "from Robert_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameters for the workflow\n",
    "\n",
    "# define csv file that contains the database (without the .csv extension) and the response value\n",
    "w_dir = os.getcwd()\n",
    "\n",
    "# name of the csv containing the database without the CSV extension. For example: csv_name = 'Phenolic_data' \n",
    "csv_name = 'Robert_example'\n",
    "\n",
    "# name of the csv file that will contain the optimal parameters\n",
    "name_csv_hyperopt = 'Predictor_parameters'\n",
    "\n",
    "# specify the response value (y), for example: response_value = 'activation_barrier_kcal/mol'\n",
    "response_value = 'Target_values'\n",
    "\n",
    "# specify columns of the csv to drop from the descriptors but to keep in the final database\n",
    "# (i.e. reaction names). For example: fixed_descriptors = ['Name','SMILES','YSI/MW','YSI','CN','MW','weakest_bondtype'].\n",
    "# If there are not descriptors to discard, just use fixed_descriptors = []\n",
    "fixed_descriptors = ['Name']\n",
    "\n",
    "# convert columns with strings into categorical values using 1,2,3... (alternative\n",
    "# to one-hot encoding that the code uses by default)\n",
    "categorical_mode = False\n",
    "\n",
    "# activate with correlation_filter = True\n",
    "correlation_filter = True\n",
    "\n",
    "# threshold values for the correlation filters (if correlation_filter = True)\n",
    "correlation_y_threshold = 0.02 # (only use descriptors that correlate with R**2 > 0.02 with the response value)\n",
    "correlation_x_threshold = 0.85 # (only use descriptors that don't correlate with R**2 > 0.85 with other descriptors)\n",
    "\n",
    "# training set proportion\n",
    "training_size = [90,80,70,60]\n",
    "# training_size = [60,80] # relative to the training set proportion (i.e. 40 = 40% training data)\n",
    "\n",
    "# mode for splitting data. Methods available:\n",
    "# 1. k-neighbours clustering-based splitting (KN)\n",
    "# 2. random splitting (RND)\n",
    "split_mode = 'KN'\n",
    "\n",
    "# parameters to be optimized. Different types of regressor models are supported:\n",
    "# 1. Random forests ('RF')\n",
    "# 2. Multivariate lineal models ('MVL')\n",
    "# 3. Gradient boosting ('GB')\n",
    "# 4. AdaBoost regressor ('AdaB')\n",
    "# 5. MLP regressor neural network ('NN')    \n",
    "# 6. Voting regressor combining RF, GB and NN ('VR')\n",
    "model_type = ['RF', 'GB', 'AdaB','VR']\n",
    "# model_type = ['RF', 'GB']\n",
    "\n",
    "# type of prediction:\n",
    "# 1. Regressor ('reg')\n",
    "# 2. Classifier ('clas')    \n",
    "prediction_type = 'reg'\n",
    "\n",
    "# random seed used in the ML predictor models\n",
    "random_init = 0\n",
    "\n",
    "# Number of epochs for the hyperopt optimization\n",
    "n_epochs = 5\n",
    "\n",
    "# sets the number of times a feature is randomly shuffled and returns a sample of feature importances (standard from Sklearn webpage: 30)\n",
    "n_repeats = 30\n",
    "\n",
    "# the PFI filter is X% of the model's score (% adjusted with per_cent_PFI_filter, 0.04 = 4%)\n",
    "# WARNING! For regression, a value of 0.04 is recommended. For classification, \n",
    "# a value of 0 is recommended. Turn this option off with PFI_filtering = False\n",
    "PFI_filtering = True\n",
    "if prediction_type == 'reg':\n",
    "    per_cent_PFI_filter = 0.04\n",
    "if prediction_type == 'clas':\n",
    "    per_cent_PFI_filter = 0\n",
    "\n",
    "# number of k-folds for cross validation\n",
    "cv_kfold = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excluded parameters:\n",
      "x1 : R**2 = 1.0 with x3\n",
      "x1 : R**2 = 0.96 with x6\n",
      "x3 : R**2 = 0.95 with x6\n",
      "\n",
      "Successfully created 37 datapoints.\n",
      "\n",
      "\n",
      "Descriptors used after correlation filters:\n",
      "x2\n",
      "x5\n",
      "x6\n",
      "x7\n",
      "x8\n",
      "x9\n",
      "x10\n",
      "x11\n",
      "Csub-Csub\n",
      "Csub-H\n",
      "Csub-O\n",
      "H-O\n"
     ]
    }
   ],
   "source": [
    "# remove correlated variables and noise (variables that do not correlate with the y values)\n",
    "\n",
    "DFT_parameters = pd.read_csv(csv_name+'.csv')\n",
    "\n",
    "# converts all columns with strings into categorical values (one hot encoding\n",
    "# by default, can be set to numerical 1,2,3... with categorical_mode = True).\n",
    "# Troubleshooting! For one-hot encoding, don't use variable names that are\n",
    "# also column headers! 9I.E. DESCRIPTOR \"C_atom\" contain C2 as a value,\n",
    "# but C2 is already a header of a different column in the database. Same applies\n",
    "# for multiple columns containing the same variable names.\n",
    "\n",
    "descriptors_to_drop = []\n",
    "for column in DFT_parameters.columns:\n",
    "    if column not in fixed_descriptors:\n",
    "        if(DFT_parameters[column].dtype == 'object'):\n",
    "            descriptors_to_drop.append(column)\n",
    "            if categorical_mode:\n",
    "                \n",
    "                DFT_parameters[column] = DFT_parameters[column].astype('category')\n",
    "                DFT_parameters[column] = DFT_parameters[column].cat.codes\n",
    "            else:\n",
    "                labels = DFT_parameters[column].unique()\n",
    "                dummies = pd.get_dummies(DFT_parameters[column])\n",
    "                DFT_parameters_filtered = DFT_parameters.drop(column, axis=1)\n",
    "                DFT_parameters = pd.concat([DFT_parameters, dummies], axis=1)\n",
    "\n",
    "if correlation_filter:\n",
    "    descriptors_to_drop = correlation_filter_fun(DFT_parameters,correlation_y_threshold,correlation_x_threshold,fixed_descriptors,descriptors_to_drop,response_value)\n",
    "\n",
    "# this parts allows to drop any descriptor that we don't want to use\n",
    "DFT_parameters_filtered = DFT_parameters.drop(descriptors_to_drop, axis=1)\n",
    "\n",
    "print('\\nSuccessfully created '+ str(len(DFT_parameters[response_value])) + ' datapoints.\\n')\n",
    "print('\\nDescriptors used after correlation filters:')\n",
    "\n",
    "DFT_parameters_filter_print = DFT_parameters_filtered.drop(fixed_descriptors, axis=1)\n",
    "for _,column in enumerate(DFT_parameters_filter_print.columns):\n",
    "    if column != response_value:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate fixed descriptors and create X and y dataframes\n",
    "fixed_data = DFT_parameters_filtered[fixed_descriptors]\n",
    "\n",
    "fixed_descriptors.append(response_value)\n",
    "X = DFT_parameters_filtered.drop(fixed_descriptors, axis=1)\n",
    "y = DFT_parameters_filtered[response_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [106], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# data splitting into training and validation sets\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mif\u001b[39;00m split_mode \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mKN\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mRND\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m----> 5\u001b[0m     X_train, y_train, X_validation, y_validation, training_points \u001b[39m=\u001b[39m data_split(X,y,training_size,random_init,split_mode)\n\u001b[0;32m      7\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mx  Select a valid method for splitting data (options: KN, RMD)!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\robert\\Robert_functions.py:74\u001b[0m, in \u001b[0;36mdata_split\u001b[1;34m(X_split, y_split, train_partition, random_seed, split_mode)\u001b[0m\n\u001b[0;32m     71\u001b[0m     Xstds \u001b[39m=\u001b[39m X_split\u001b[39m.\u001b[39mstd(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     72\u001b[0m     X_scaled_split \u001b[39m=\u001b[39m (X_split \u001b[39m-\u001b[39m Xmeans) \u001b[39m/\u001b[39m Xstds\n\u001b[1;32m---> 74\u001b[0m     training_points \u001b[39m=\u001b[39m k_neigh(X_scaled_split,training_folds_split,random_seed,y_split)\n\u001b[0;32m     76\u001b[0m \u001b[39melif\u001b[39;00m split_mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRND\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     77\u001b[0m     n_of_points \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(X_split)\u001b[39m*\u001b[39m(training_folds_split\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\robert\\Robert_functions.py:28\u001b[0m, in \u001b[0;36mk_neigh\u001b[1;34m(X_scaled_split, training_folds_split, random_seed, y_split)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mk_neigh\u001b[39m(X_scaled_split,training_folds_split,random_seed,y_split):\n\u001b[0;32m     24\u001b[0m     \n\u001b[0;32m     25\u001b[0m     \u001b[39m# number of clusters in the training set from the k-neighbours clustering (based on the\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39m# training set size specified above)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     X_scaled_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(X_scaled_split)\n\u001b[1;32m---> 28\u001b[0m     number_of_clusters \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(X_scaled_split)\u001b[39m*\u001b[39m(training_folds_split\u001b[39m/\u001b[39;49m\u001b[39m100\u001b[39;49m))\n\u001b[0;32m     30\u001b[0m     \u001b[39m# to avoid points from the validation set outside the training set, the 2 first training\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[39m# points are automatically set as the 2 points with minimum/maximum response value\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     training_points \u001b[39m=\u001b[39m [y_split\u001b[39m.\u001b[39midxmin(),y_split\u001b[39m.\u001b[39midxmax()]\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "# data splitting into training and validation sets\n",
    "    \n",
    "if split_mode in ['KN','RND']:\n",
    "\n",
    "    X_train, y_train, X_validation, y_validation, training_points = data_split(X,y,training_size,random_init,split_mode)\n",
    "\n",
    "else:\n",
    "    print('x  Select a valid method for splitting data (options: KN, RMD)!')\n",
    "    sys.exit()\n",
    "\n",
    "fixed_data_train = fixed_data.iloc[training_points]\n",
    "fixed_data_validation = fixed_data.drop(training_points)\n",
    "print(X_train)\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean = X_train.mean(axis=0)\n",
    "Xstd = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - Xmean) / Xstd\n",
    "X_validation_scaled = (X_validation - Xmean) / Xstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 32.40trial/s, best loss: 0.15433454360636192]\n",
      "0.22784597514314472\n",
      "0.22784597514314472\n",
      "100%|██████████| 5/5 [00:00<00:00, 14.76trial/s, best loss: 0.16145605724614776]\n",
      "0.16145605724614776\n",
      "0.6192519303366028\n",
      "100%|██████████| 5/5 [00:00<00:00, 24.99trial/s, best loss: 0.22615639400665158]\n",
      "0.39209973445224877\n",
      "0.39209973445224877\n",
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:01<00:01,  1.59trial/s, best loss: 0.16436963622598907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:01<00:00,  2.37trial/s, best loss: 0.16436963622598907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.36trial/s, best loss: 0.14803288852069404]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14803288852069404\n",
      "0.4863562516903175\n",
      "100%|██████████| 5/5 [00:00<00:00, 40.41trial/s, best loss: 0.129822432847353]\n",
      "0.15625678107676866\n",
      "0.2690848050622404\n",
      "100%|██████████| 5/5 [00:00<00:00, 14.63trial/s, best loss: 0.12330528822327]   \n",
      "0.12330528822327\n",
      "0.18699734823421044\n",
      "100%|██████████| 5/5 [00:00<00:00, 24.33trial/s, best loss: 0.2446721564035851]\n",
      "0.2878068693971932\n",
      "0.1662286559663152\n",
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:02,  1.97trial/s, best loss: 0.14275590504366625]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:01<00:01,  1.85trial/s, best loss: 0.14275590504366625]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:01<00:00,  2.77trial/s, best loss: 0.14275590504366625]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.82trial/s, best loss: 0.12324562097253842]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12324562097253842\n",
      "0.12728855577833934\n",
      "100%|██████████| 5/5 [00:00<00:00, 39.48trial/s, best loss: 0.20715117048843193]\n",
      "0.41545443774762036\n",
      "0.23159024654214508\n",
      "100%|██████████| 5/5 [00:00<00:00, 17.78trial/s, best loss: 0.2765068898894078]\n",
      "0.2765068898894078\n",
      "0.26600745318673286\n",
      "100%|██████████| 5/5 [00:00<00:00, 24.40trial/s, best loss: 0.2789871201090729]\n",
      "0.35105011462260755\n",
      "0.2186316448169174\n",
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:02,  1.96trial/s, best loss: 0.21685869090014978]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:01<00:01,  1.82trial/s, best loss: 0.21685869090014978]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:01<00:00,  2.72trial/s, best loss: 0.21685869090014978]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.75trial/s, best loss: 0.20169442504125057]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20169442504125057\n",
      "0.20479783902358706\n",
      "100%|██████████| 5/5 [00:00<00:00, 41.50trial/s, best loss: 0.2222170828214671]\n",
      "0.2222170828214671\n",
      "0.1573192848388959\n",
      "100%|██████████| 5/5 [00:00<00:00, 19.33trial/s, best loss: 0.1996192977283523] \n",
      "0.1996192977283523\n",
      "0.24685292340111525\n",
      "100%|██████████| 5/5 [00:00<00:00, 23.99trial/s, best loss: 0.17115671994549644]\n",
      "0.317312647803555\n",
      "0.19017111927309055\n",
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:02,  1.86trial/s, best loss: 0.16923012200046342]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:01<00:01,  1.70trial/s, best loss: 0.1620212230897947] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:01<00:00,  2.58trial/s, best loss: 0.1620212230897947]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.49trial/s, best loss: 0.1620212230897947]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17093859048398485\n",
      "0.17872713089617162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n",
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x  Warning! Error lower without PFI filter (no PFI: RMSE = 0.12 with 12 variables; with PFI filter: 0.13 with 12 variables consider using PFI_filtering=False\n",
      "The optimal model is ['VR', 80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if training_size == ['all']:\n",
    "    training_size = [90,80,70,60,50,40,30,20,10]\n",
    "    \n",
    "size_data= [ ]\n",
    "for size in training_size:\n",
    "    size_data_indiv = []\n",
    "        \n",
    "    if split_mode in ['KN','RND']:\n",
    "\n",
    "        X_train, y_train, X_validation, y_validation, training_points = data_split(X,y,size,random_init,split_mode)\n",
    "\n",
    "    else:\n",
    "        print('x  Select a valid method for splitting data (options: KN, RMD)!')\n",
    "        sys.exit()\n",
    "\n",
    "    fixed_data_train = fixed_data.iloc[training_points]\n",
    "    fixed_data_validation = fixed_data.drop(training_points)\n",
    "    #print(X_train)\n",
    "    # standardizes the data sets using the mean and standard dev from the train set\n",
    "    Xmean = X_train.mean(axis=0)\n",
    "    Xstd = X_train.std(axis=0)\n",
    "    X_train_scaled = (X_train - Xmean) / Xstd\n",
    "    X_validation_scaled = (X_validation - Xmean) / Xstd\n",
    "    if model_type == ['all']:\n",
    "        model_type = ['RF','GB','AdaB','MVL','NN','VR']\n",
    "        \n",
    "    models_data = []\n",
    "    for MODEL in model_type:\n",
    "        models_data_indiv = []\n",
    "        # hyperopt process including k-neighbours-based splitting of the data\n",
    "        hyperopt_process = run_hyperopt(n_epochs, MODEL, X, size, prediction_type, random_init, w_dir, X_train_scaled, y_train, X_validation_scaled, y_validation, name_csv_hyperopt)\n",
    "\n",
    "        # read the csv to load and print information about the parameters\n",
    "        best_parameters_df = pd.read_csv(name_csv_hyperopt+'.csv')\n",
    "    \n",
    "        # print information about the hyperopt process\n",
    "        #print_hyperopt_params(MODEL,best_parameters_df,training_size,w_dir)\n",
    "        if prediction_type == 'reg':\n",
    "        # calculate R2, MAE and RMSE for train and validation sets\n",
    "            r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,_,_ = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,prediction_type,size)\n",
    "        # calculates k-fold cross validation\n",
    "            cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,prediction_type,cv_kfold)\n",
    "        # print stats\n",
    "        # print_model_stats(MODEL,X_train_scaled,X_validation_scaled,r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,prediction_type,cv_score,cv_kfold,None)\n",
    "\n",
    "        elif prediction_type == 'clas':\n",
    "        # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "            accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,_,_ = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,prediction_type,size)\n",
    "        # calculates k-fold cross validation\n",
    "            cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,prediction_type,cv_kfold)\n",
    "        # print stats\n",
    "            #print_model_stats(MODEL,X_train_scaled,X_validation_scaled,accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,prediction_type,cv_score,cv_kfold,None)\n",
    "        # calculate the permutation feature importance (PFI) of the descriptors in the \n",
    "        # model and generates a new dataset\n",
    "        print(rmse_validation)\n",
    "        # PFI function\n",
    "        combined_descriptor_list = PFI_workflow(X,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,n_repeats,per_cent_PFI_filter,False,prediction_type,PFI_filtering)\n",
    "\n",
    "        # creates X and y sets\n",
    "        # creates a database with the most important descriptors after PFI\n",
    "\n",
    "        df_PFI_model = pd.DataFrame()\n",
    "        df_PFI_model[response_value] = DFT_parameters_filtered[response_value]\n",
    "\n",
    "        for i,column in enumerate(DFT_parameters_filtered.columns):\n",
    "            if column in combined_descriptor_list:\n",
    "                df_PFI_model[column] = DFT_parameters_filtered[column]\n",
    "\n",
    "        X_PFI = df_PFI_model.drop([response_value], axis=1)\n",
    "        y_PFI = df_PFI_model[response_value]\n",
    "\n",
    "        # k-neighbours-based data splitting using previous training points\n",
    "        X_train_PFI = X_PFI.iloc[training_points]\n",
    "        y_train_PFI = y_PFI.iloc[training_points]\n",
    "        X_validation_PFI = X_PFI.drop(training_points)\n",
    "        y_validation_PFI = y_PFI.drop(training_points)\n",
    "\n",
    "        # standardizes the data sets using the mean and standard dev from the train set\n",
    "        Xmean = X_train_PFI.mean(axis=0)\n",
    "        Xstd = X_train_PFI.std(axis=0)\n",
    "        X_train_PFI_scaled = (X_train_PFI - Xmean) / Xstd\n",
    "        X_validation_PFI_scaled = (X_validation_PFI - Xmean) / Xstd\n",
    "        # run the best model from hyperopt and calculates its efficiency using only \n",
    "        # the most important features from the PFI analysis\n",
    "        try:\n",
    "            if int(best_parameters_df['max_features'][0]) > len(X_PFI.columns):\n",
    "                best_parameters_df.at[0,'max_features'] = len(X_PFI.columns)\n",
    "                # replace the value in the parameters csv\n",
    "                export_param_excel = best_parameters_df.to_csv(name_csv_hyperopt+'.csv', index = None, header=True)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        if prediction_type == 'reg':\n",
    "            # calculate R2, MAE and RMSE for train and validation sets\n",
    "            r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,prediction_type,size)\n",
    "            print(rmse_validation_PFI)\n",
    "            # calculates k-fold cross validation\n",
    "            cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,prediction_type,cv_kfold)\n",
    "            # print stats\n",
    "            #print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,prediction_type,cv_score,cv_kfold,'Robert_results.txt')\n",
    "            # data of the model\n",
    "            models_data_indiv = [MODEL, best_parameters_df, r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,rmse_validation,X_train_PFI_scaled,X_train_scaled,y_pred_train_PFI,y_pred_validation_PFI, cv_score]\n",
    "\n",
    "        elif prediction_type == 'clas':\n",
    "            # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "            accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,prediction_type,size)\n",
    "            # calculates k-fold cross validation\n",
    "            cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,prediction_type,cv_kfold)\n",
    "            # print stats\n",
    "            #print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,prediction_type,cv_score,cv_kfold,'Robert_results.txt')\n",
    "            # data of the model\n",
    "            models_data_indiv = [MODEL, best_parameters_df, accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI, cv_score]\n",
    "            \n",
    "        models_data.append(models_data_indiv)\n",
    "\n",
    "    size_data_indiv = [size,models_data]\n",
    "    size_data.append(size_data_indiv)\n",
    "\n",
    "# Obtain the model/training size with the minimum rmse_train_PFI\n",
    "def optimal_model(size_data):\n",
    "    min_rmse=10000000000\n",
    "    rmse_no_PFI = []\n",
    "    for models_data in size_data:\n",
    "        for rmse_validation in models_data[1]:\n",
    "            # rmse from PFI models\n",
    "            if rmse_validation[7] < min_rmse:   \n",
    "                min_rmse=rmse_validation[7]\n",
    "                best_model=[rmse_validation[0], models_data[0]]\n",
    "            # rmse from models without the PFI filter\n",
    "            rmse_no_PFI.append(rmse_validation[8])\n",
    "    \n",
    "    if min(rmse_no_PFI) < min_rmse:\n",
    "        # print(size_data[0][1][0][9].columns)\n",
    "        len_PFI = len(size_data[0][1][0][9].columns)\n",
    "        len_no_PFI = len(size_data[0][1][0][10].columns)\n",
    "        print(f\"x  Warning! Error lower without PFI filter (no PFI: RMSE = {round(min(rmse_no_PFI),2)} with {len_no_PFI} variables; with PFI filter: {round(min_rmse,2)} with {len_PFI} variables consider using PFI_filtering=False\")    \n",
    "        \n",
    "    return best_model \n",
    "best_model = optimal_model(size_data)\n",
    "print(f\"The optimal model is {best_model}\")\n",
    "\n",
    "#Obtaning all rmse_validation_PFI values from all models/training size\n",
    "plot_data=[]\n",
    "for models_data in size_data:\n",
    "    plot_data_indv=0\n",
    "    plot_data_indiv = []\n",
    "    for rmse_validation_PFI in models_data[1]:  \n",
    "        plot_data_indiv.append(rmse_validation_PFI[7])\n",
    "    plot_data.append(plot_data_indiv)\n",
    "\n",
    "#pd.DataFrame(models_data)\n",
    "df_plot = pd.DataFrame(plot_data)\n",
    "df_plot.columns = [model_type]\n",
    "df_plot.index = [training_size]\n",
    "df_plot = df_plot.sort_index(ascending=False)\n",
    "\n",
    "# print(df_plot)\n",
    "# sb.heatmap(df_plot, annot=True,linewidth=.5,cmap=\"crest\")\n",
    "ax = sb.heatmap(df_plot, annot=True,linewidth=.5,cmap=\"Blues\",cbar_kws={'label': 'RMSE Validation'})\n",
    "ax.set(xlabel=\"Model type\", ylabel=\"Training size\")\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GB\n",
      "k-neighbours-based training, validation and test sets have been created with this distribution:\n",
      "Training points: 29\n",
      "k-neighbours-based training: R2 = 1.0; MAE = 0.0; RMSE = 0.0\n",
      "5-fold cross validation: 0.72 ± 0.23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the best model from hyperopt and calculates its efficiency\n",
    "\n",
    "if prediction_type == 'reg':\n",
    "    # calculate R2, MAE and RMSE for train and validation sets\n",
    "    r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,_,_ = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(MODEL,X_train_scaled,X_validation_scaled,r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,prediction_type,cv_score,cv_kfold,None)\n",
    "\n",
    "elif prediction_type == 'clas':\n",
    "    # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "    accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,_,_ = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(MODEL,X_train_scaled,X_validation_scaled,accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,prediction_type,cv_score,cv_kfold,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the permutation feature importance (PFI) of the descriptors in the \n",
    "# model and generates a new dataset\n",
    "\n",
    "# PFI function\n",
    "combined_descriptor_list = PFI_workflow(X,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,n_repeats,per_cent_PFI_filter,False,prediction_type,PFI_filtering)\n",
    "\n",
    "# creates X and y sets\n",
    "# creates a database with the most important descriptors after PFI\n",
    "\n",
    "df_PFI_model = pd.DataFrame()\n",
    "df_PFI_model[response_value] = DFT_parameters_filtered[response_value]\n",
    "\n",
    "for i,column in enumerate(DFT_parameters_filtered.columns):\n",
    "    if column in combined_descriptor_list:\n",
    "        df_PFI_model[column] = DFT_parameters_filtered[column]\n",
    "\n",
    "X_PFI = df_PFI_model.drop([response_value], axis=1)\n",
    "y_PFI = df_PFI_model[response_value]\n",
    "\n",
    "# k-neighbours-based data splitting using previous training points\n",
    "X_train_PFI = X_PFI.iloc[training_points]\n",
    "y_train_PFI = y_PFI.iloc[training_points]\n",
    "X_validation_PFI = X_PFI.drop(training_points)\n",
    "y_validation_PFI = y_PFI.drop(training_points)\n",
    "\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean = X_train_PFI.mean(axis=0)\n",
    "Xstd = X_train_PFI.std(axis=0)\n",
    "X_train_PFI_scaled = (X_train_PFI - Xmean) / Xstd\n",
    "X_validation_PFI_scaled = (X_validation_PFI - Xmean) / Xstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RF\n",
      "k-neighbours-based training, validation and test sets have been created with this distribution:\n",
      "Training points: 29\n",
      "Validation points: 8\n",
      "\n",
      "k-neighbours-based training: R2 = 0.98; MAE = 0.06; RMSE = 0.09\n",
      "5-fold cross validation: 0.76 ± 0.15\n",
      "k-neighbours-based validation: R2 = 0.97; MAE = 0.1; RMSE = 0.12\n"
     ]
    }
   ],
   "source": [
    "# run the best model from hyperopt and calculates its efficiency using only \n",
    "# the most important features from the PFI analysis\n",
    "if int(best_parameters_df['max_features'][0]) > len(X_PFI.columns):\n",
    "    best_parameters_df.at[0,'max_features'] = len(X_PFI.columns)\n",
    "    # replace the value in the parameters csv\n",
    "    export_param_excel = best_parameters_df.to_csv(name_csv_hyperopt+'.csv', index = None, header=True)\n",
    "\n",
    "if prediction_type == 'reg':\n",
    "    # calculate R2, MAE and RMSE for train and validation sets\n",
    "    r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,prediction_type,cv_score,cv_kfold,'Robert_results.txt')\n",
    "\n",
    "elif prediction_type == 'clas':\n",
    "    # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "    accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,prediction_type,cv_score,cv_kfold,'Robert_results.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'predictor_model_fun' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# calculate the permutation feature importance (PFI) of the final model and\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# saves the data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m combined_descriptor_list \u001b[39m=\u001b[39m PFI_workflow(X_PFI,model_type,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,n_repeats,\u001b[39m0\u001b[39m,\u001b[39mTrue\u001b[39;00m,prediction_type,PFI_filtering)\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\robert\\Robert_functions.py:778\u001b[0m, in \u001b[0;36mPFI_workflow\u001b[1;34m(X_PFI_fun, model_type_PFI_fun, best_parameters_df_PFI_fun, X_train_scaled_PFI_fun, y_train_PFI_fun, X_validation_scaled_PFI_fun, y_validation_PFI_fun, n_repeats_PFI_fun, per_cent_PFI_filter_PFI_fun, save_PFI, prediction_type_fun, PFI_filtering)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m X_PFI_fun:\n\u001b[0;32m    776\u001b[0m     combined_descriptor_list\u001b[39m.\u001b[39mappend(column)\n\u001b[1;32m--> 778\u001b[0m model_perm \u001b[39m=\u001b[39m predictor_model_fun(model_type_PFI_fun, best_parameters_df_PFI_fun, \u001b[39m0\u001b[39;49m, prediction_type_fun)\n\u001b[0;32m    780\u001b[0m model_perm\u001b[39m.\u001b[39mfit(X_train_scaled_PFI_fun, y_train_PFI_fun)\n\u001b[0;32m    781\u001b[0m score_model \u001b[39m=\u001b[39m model_perm\u001b[39m.\u001b[39mscore(X_validation_scaled_PFI_fun, y_validation_PFI_fun)\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\robert\\Robert_functions.py:769\u001b[0m, in \u001b[0;36mpredictor_model_fun\u001b[1;34m(model_type_fun, best_parameters_df, random_state, prediction_type_fun)\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMultivariate models (model_type = \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mMVL\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) are not compatible with classifiers (prediction_type = \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mclas\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    767\u001b[0m         sys\u001b[39m.\u001b[39mexit()\n\u001b[1;32m--> 769\u001b[0m \u001b[39mreturn\u001b[39;00m predictor_model_fun\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'predictor_model_fun' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# calculate the permutation feature importance (PFI) of the final model and\n",
    "# saves the data\n",
    "\n",
    "combined_descriptor_list = PFI_workflow(X_PFI,model_type,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,n_repeats,0,True,prediction_type,PFI_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data in a CSV file including set column and predicted values \n",
    "\n",
    "X_train_csv = fixed_data_train.copy()\n",
    "X_validation_csv = fixed_data_validation.copy()\n",
    "\n",
    "X_train_csv[response_value] = y_train_PFI\n",
    "X_validation_csv[response_value] = y_validation_PFI\n",
    "\n",
    "X_train_csv[f'Predicted {response_value}'] = y_pred_train_PFI\n",
    "X_validation_csv[f'Predicted {response_value}'] = y_pred_validation_PFI\n",
    "\n",
    "X_train_csv = pd.concat([X_train_csv, X_train_PFI], axis=1)\n",
    "X_validation_csv = pd.concat([X_validation_csv, X_validation_PFI], axis=1)\n",
    "\n",
    "X_train_csv['Set'] = 'Training'\n",
    "X_validation_csv['Set'] = 'Validation'\n",
    "\n",
    "df_csv = pd.concat([X_train_csv, X_validation_csv], axis=0)\n",
    "\n",
    "# creates an Excel database with only the most important descriptors used by the model\n",
    "export_param_excel = df_csv.to_csv(f'{csv_name}_final_dataset.csv', index = None, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and test sets\n",
    "\n",
    "if prediction_type == 'reg':\n",
    "    sb.set(font_scale=1.2, style=\"ticks\") #set styling preferences\n",
    "\n",
    "    Plotdata_train_PFI = {'y_train_PFI': y_train_PFI, 'y_pred_train_PFI': y_pred_train_PFI} \n",
    "    Plotdata_validation_PFI = {'y_validation_PFI': y_validation_PFI, 'y_pred_validation_PFI': y_pred_validation_PFI}\n",
    "\n",
    "    df_train_PFI = pd.DataFrame.from_dict(Plotdata_train_PFI)\n",
    "    df_validation_PFI = pd.DataFrame.from_dict(Plotdata_validation_PFI)\n",
    "\n",
    "    # Build the plot\n",
    "    # Set up some features to plot the dots\n",
    "    color_train = 'b'\n",
    "    color_validation = 'orange'\n",
    "    size = 30\n",
    "    alpha = 1 # from 0 (transparent) to 1 (opaque)\n",
    "\n",
    "    # Create subplot with a certain size and title\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "    # Set styling preferences\n",
    "    sb.set(font_scale=1.2, style=\"ticks\")\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    # title of the graph\n",
    "    total_points = len(y_train_PFI)+len(y_validation_PFI)\n",
    "    train_proportion = len(y_train_PFI)/total_points\n",
    "    validation_proportion = len(y_validation_PFI)/total_points\n",
    "    ratios =  str(round(train_proportion,2)*100)+':'+str(round(validation_proportion,2)*100)\n",
    "    title_text = model_type+' model with train:validation ('+ratios+') of '+str(total_points)+' datapoints'\n",
    "    \n",
    "    plt.text(0.5, 1.08, title_text, horizontalalignment='center',\n",
    "         fontsize=14, fontweight='bold', transform = ax.transAxes)\n",
    "\n",
    "    # Plot the data\n",
    "    points_train = ax.scatter(df_train_PFI[\"y_train_PFI\"], df_train_PFI[\"y_pred_train_PFI\"],\n",
    "                c = color_train, s = size, edgecolor = 'k', linewidths = 0.8, alpha = alpha, zorder=2)\n",
    "\n",
    "    points_validation = ax.scatter(df_validation_PFI[\"y_validation_PFI\"], df_validation_PFI[\"y_pred_validation_PFI\"],\n",
    "                c = color_validation, s = size, edgecolor = 'k', linewidths = 0.8, alpha = alpha, zorder=2)\n",
    "\n",
    "    # Put a legend below current axis\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.17),\n",
    "            fancybox=True, shadow=True, ncol=5, labels=['Training','Validation'])\n",
    "\n",
    "    # Add the regression line with a confidence interval based on the training sets\n",
    "    plot = sb.regplot(\"y_train_PFI\", \"y_pred_train_PFI\", data=df_train_PFI, scatter=False, color=\".1\", \n",
    "                    truncate = True, ax=ax)\n",
    "\n",
    "    # Title of the axis\n",
    "    plot = ax.set(ylabel=f'Predicted {response_value}', xlabel=f'{response_value} from database')\n",
    "    \n",
    "    # Add gridlines\n",
    "    ax.grid(linestyle='--', linewidth=1)\n",
    "\n",
    "    # set limits\n",
    "    size_space = 0.1*abs(min(y_train_PFI)-max(y_train_PFI))\n",
    "    if min(y_train_PFI) < min(y_validation_PFI):\n",
    "        min_value_graph = min(y_train_PFI)-size_space\n",
    "    else:\n",
    "        min_value_graph = min(y_validation_PFI)-size_space\n",
    "        \n",
    "    if max(y_train_PFI) > max(y_validation_PFI):\n",
    "        max_value_graph = max(y_train_PFI)+size_space\n",
    "    else:\n",
    "        max_value_graph = max(y_validation_PFI)+size_space\n",
    "        \n",
    "    plt.xlim(min_value_graph, max_value_graph)\n",
    "    plt.ylim(min_value_graph, max_value_graph)\n",
    "        \n",
    "    # save the plot a png image, type True\n",
    "    plt.savefig('Predicted vs database values.png', dpi=400, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print('\\nThe corresponding graph was saved in '+w_dir+'.')\n",
    "\n",
    "elif prediction_type == 'clas':\n",
    "    predictor_model = predictor_model_fun(model_type, best_parameters_df, random_init, prediction_type)\n",
    "\n",
    "    predictor_model.fit(X_train_PFI_scaled, y_train_PFI)\n",
    "\n",
    "    plot_confusion_matrix(predictor_model, X_validation_PFI_scaled, y_validation_PFI,cmap='Blues') \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run x- and y-shuffle statistical tests\n",
    "random.seed(a=random_init)\n",
    "\n",
    "# load original data\n",
    "df_tests_model = pd.read_csv(csv_name+'_final_dataset.csv')\n",
    "\n",
    "training_data = df_tests_model[df_tests_model.Set == 'Training']\n",
    "validation_data = df_tests_model[df_tests_model.Set == 'Validation']\n",
    "\n",
    "# parameters to discard from the csv\n",
    "shuffle_drops = fixed_descriptors.copy()\n",
    "shuffle_drops.append('Set')\n",
    "shuffle_drops.append('Predicted '+response_value)\n",
    "\n",
    "X_train_tests = training_data.drop(shuffle_drops, axis=1)\n",
    "X_validation_tests = validation_data.drop(shuffle_drops, axis=1)\n",
    "\n",
    "y_train_tests = training_data[response_value]\n",
    "y_validation_tests = validation_data[response_value]\n",
    "\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean_tests = X_train_tests.mean(axis=0)\n",
    "Xstd_tests = X_train_tests.std(axis=0)\n",
    "X_train_tests_scaled = (X_train_tests - Xmean) / Xstd\n",
    "X_validation_tests_scaled = (X_validation_tests - Xmean) / Xstd\n",
    "\n",
    "y_train_tests = training_data[response_value]\n",
    "y_validation_tests = validation_data[response_value]\n",
    "\n",
    "# x shuffle test\n",
    "X_train_shuffled = training_data.drop(shuffle_drops, axis=1)\n",
    "X_validation_shuffled = validation_data.drop(shuffle_drops, axis=1)\n",
    "\n",
    "# fixed_descriptors\n",
    "X_train_shuffled = np.asarray(X_train_shuffled)\n",
    "X_validation_shuffled = np.asarray(X_validation_shuffled)\n",
    "\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean = X_train_shuffled.mean(axis=0)\n",
    "Xstd = X_train_shuffled.std(axis=0)\n",
    "X_train_shuffled_scaled = (X_train_shuffled - Xmean) / Xstd\n",
    "X_validation_shuffled_scaled = (X_validation_shuffled - Xmean) / Xstd\n",
    "\n",
    "for row in X_train_shuffled_scaled:\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    \n",
    "for row in X_validation_shuffled_scaled:\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "\n",
    "print('\\nResults from the x-shuffle test')\n",
    "r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,y_pred_train_tests,y_pred_validation_tests = predictor_workflow(random_init,model_type,best_parameters_df,X_train_shuffled_scaled,y_train_tests,X_validation_shuffled_scaled,y_validation_tests,prediction_type,training_size)\n",
    "cv_score_x_shuffle = cross_val_calc(random_init,model_type,best_parameters_df,X_train_shuffled_scaled,y_train_tests,prediction_type,cv_kfold)\n",
    "print_model_stats(model_type,X_train_tests_scaled,X_validation_tests_scaled,r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,prediction_type,cv_score_x_shuffle,cv_kfold,'Robert_results_x-shuffle.txt')\n",
    "\n",
    "# y shuffle test\n",
    "y_train_shuffled = y_train_tests.copy()\n",
    "y_validation_shuffled = y_validation_tests.copy()\n",
    "\n",
    "y_train_shuffled = np.asarray(y_train_shuffled)   \n",
    "y_validation_shuffled = np.asarray(y_validation_shuffled) \n",
    "\n",
    "random.shuffle(y_train_shuffled)\n",
    "random.shuffle(y_validation_shuffled)\n",
    "\n",
    "print('\\nResults from the y-shuffle test')\n",
    "r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,y_pred_train_tests,y_pred_validation_tests = predictor_workflow(random_init,model_type,best_parameters_df,X_train_tests_scaled,y_train_shuffled,X_validation_tests_scaled,y_validation_shuffled,prediction_type,training_size)\n",
    "cv_score_y_shuffle = cross_val_calc(random_init,model_type,best_parameters_df,X_train_tests_scaled,y_train_shuffled,prediction_type,cv_kfold)\n",
    "print_model_stats(model_type,X_train_tests_scaled,X_validation_tests_scaled,r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,prediction_type,cv_score_y_shuffle,cv_kfold,'Robert_results_y-shuffle.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c5487727bc19a7756b0b46e65906cd028f983eb1d2958fa31410245bab4c89c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
