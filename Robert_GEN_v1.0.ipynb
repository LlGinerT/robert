{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import random\n",
    "from Robert_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameters for the workflow\n",
    "\n",
    "# define csv file that contains the database (without the .csv extension) and the response value\n",
    "w_dir = os.getcwd()\n",
    "\n",
    "# name of the csv containing the database without the CSV extension. For example: csv_name = 'Phenolic_data' \n",
    "csv_name = 'CSV_NAME'\n",
    "\n",
    "# name of the csv file that will contain the optimal parameters\n",
    "name_csv_hyperopt = 'Predictor_parameters'\n",
    "\n",
    "# specify the response value (y), for example: response_value = 'activation_barrier_kcal/mol'\n",
    "response_value = 'YOUR_Y_VALUE'\n",
    "\n",
    "# specify columns of the csv to drop from the descriptors but to keep in the final database\n",
    "# (i.e. reaction names). For example: fixed_descriptors = ['Name','SMILES','YSI/MW','YSI','CN','MW','weakest_bondtype'].\n",
    "# If there are not descriptors to discard, just use fixed_descriptors = []\n",
    "fixed_descriptors = ['DESC1','DESC2','ETC']\n",
    "\n",
    "# convert columns with strings into categorical values using 1,2,3... (alternative\n",
    "# to one-hot encoding that the code uses by default)\n",
    "categorical_mode = False\n",
    "\n",
    "# activate with correlation_filter = True\n",
    "correlation_filter = True\n",
    "\n",
    "# threshold values for the correlation filters (if correlation_filter = True)\n",
    "correlation_y_threshold = 0.02 # (only use descriptors that correlate with R**2 > 0.02 with the response value)\n",
    "correlation_x_threshold = 0.85 # (only use descriptors that don't correlate with R**2 > 0.85 with other descriptors)\n",
    "\n",
    "# training set proportion\n",
    "training_size = 80 # relative to the training set proportion (i.e. 40 = 40% training data)\n",
    "\n",
    "# mode for splitting data. Methods available:\n",
    "# 1. k-neighbours clustering-based splitting (KN)\n",
    "# 2. random splitting (RND)\n",
    "split_mode = 'KN'\n",
    "\n",
    "# parameters to be optimized. Different types of regressor models are supported:\n",
    "# 1. Random forests ('RF')\n",
    "# 2. Multivariate lineal models ('MVL')\n",
    "# 3. Gradient boosting ('GB')\n",
    "# 4. AdaBoost regressor ('AdaB')\n",
    "# 5. MLP regressor neural network ('NN')\n",
    "# 6. Voting regressor combining RF, GB and NN ('VR')\n",
    "model_type = 'RF'\n",
    "\n",
    "# type of prediction:\n",
    "# 1. Regressor ('reg')\n",
    "# 2. Classifier ('clas')\n",
    "prediction_type = 'reg'\n",
    "\n",
    "# random seed used in the ML predictor models\n",
    "random_init = 0\n",
    "\n",
    "# Number of epochs for the hyperopt optimization\n",
    "n_epochs = 100\n",
    "\n",
    "# sets the number of times a feature is randomly shuffled and returns a sample of feature importances (standard from Sklearn webpage: 30)\n",
    "n_repeats = 30\n",
    "\n",
    "# the PFI filter is X% of the model's score (% adjusted with per_cent_PFI_filter, 0.04 = 4%)\n",
    "# WARNING! For regression, a value of 0.04 is recommended. For classification, \n",
    "# a value of 0 is recommended. Turn this option off with PFI_filtering = False\n",
    "PFI_filtering = True\n",
    "if prediction_type == 'reg':\n",
    "    per_cent_PFI_filter = 0.04\n",
    "if prediction_type == 'clas':\n",
    "    per_cent_PFI_filter = 0\n",
    "\n",
    "# number of k-folds for cross validation\n",
    "cv_kfold = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove correlated variables and noise (variables that do not correlate with the y values)\n",
    "\n",
    "DFT_parameters = pd.read_csv(csv_name+'.csv')\n",
    "\n",
    "# converts all columns with strings into categorical values (one hot encoding\n",
    "# by default, can be set to numerical 1,2,3... with categorical_mode = True).\n",
    "# Troubleshooting! For one-hot encoding, don't use variable names that are\n",
    "# also column headers! 9I.E. DESCRIPTOR \"C_atom\" contain C2 as a value,\n",
    "# but C2 is already a header of a different column in the database. Same applies\n",
    "# for multiple columns containing the same variable names.\n",
    "\n",
    "descriptors_to_drop = []\n",
    "for column in DFT_parameters.columns:\n",
    "    if column not in fixed_descriptors:\n",
    "        if(DFT_parameters[column].dtype == 'object'):\n",
    "            descriptors_to_drop.append(column)\n",
    "            if categorical_mode:\n",
    "                DFT_parameters[column] = DFT_parameters[column].astype('category')\n",
    "                DFT_parameters[column] = DFT_parameters[column].cat.codes\n",
    "            else:\n",
    "                labels = DFT_parameters[column].unique()\n",
    "                dummies = pd.get_dummies(DFT_parameters[column])\n",
    "                DFT_parameters_filtered = DFT_parameters.drop(column, axis=1)\n",
    "                DFT_parameters = pd.concat([DFT_parameters, dummies], axis=1)\n",
    "\n",
    "if correlation_filter:\n",
    "    descriptors_to_drop = correlation_filter_fun(DFT_parameters,correlation_y_threshold,correlation_x_threshold,fixed_descriptors,descriptors_to_drop,response_value)\n",
    "\n",
    "# this parts allows to drop any descriptor that we don't want to use\n",
    "DFT_parameters_filtered = DFT_parameters.drop(descriptors_to_drop, axis=1)\n",
    "\n",
    "print('\\nSuccessfully created '+ str(len(DFT_parameters[response_value])) + ' datapoints.\\n')\n",
    "print('\\nDescriptors used after correlation filters:')\n",
    "\n",
    "DFT_parameters_filter_print = DFT_parameters_filtered.drop(fixed_descriptors, axis=1)\n",
    "for _,column in enumerate(DFT_parameters_filter_print.columns):\n",
    "    if column != response_value:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate fixed descriptors and create X and y dataframes\n",
    "fixed_data = DFT_parameters_filtered[fixed_descriptors]\n",
    "\n",
    "fixed_descriptors.append(response_value)\n",
    "X = DFT_parameters_filtered.drop(fixed_descriptors, axis=1)\n",
    "y = DFT_parameters_filtered[response_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting into training and validation sets\n",
    "\n",
    "if split_mode in ['KN','RND']:\n",
    "\n",
    "    X_train, y_train, X_validation, y_validation, training_points = data_split(X,y,training_size,random_init,split_mode)\n",
    "\n",
    "else:\n",
    "    print('x  Select a valid method for splitting data (options: KN, RMD)!')\n",
    "    sys.exit()\n",
    "\n",
    "fixed_data_train = fixed_data.iloc[training_points]\n",
    "fixed_data_validation = fixed_data.drop(training_points)\n",
    "print(X_train)\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean = X_train.mean(axis=0)\n",
    "Xstd = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - Xmean) / Xstd\n",
    "X_validation_scaled = (X_validation - Xmean) / Xstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperopt process including k-neighbours-based splitting of the data\n",
    "hyperopt_process = run_hyperopt(n_epochs, model_type, X, training_size, prediction_type, random_init, w_dir, X_train_scaled, y_train, X_validation_scaled, y_validation, name_csv_hyperopt)\n",
    "\n",
    "# read the csv to load and print information about the parameters\n",
    "best_parameters_df = pd.read_csv(name_csv_hyperopt+'.csv')\n",
    "\n",
    "# print information about the hyperopt process\n",
    "print_hyperopt_params(model_type,best_parameters_df,training_size,w_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the best model from hyperopt and calculates its efficiency\n",
    "\n",
    "if prediction_type == 'reg':\n",
    "    # calculate R2, MAE and RMSE for train and validation sets\n",
    "    r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,_,_ = predictor_workflow(random_init,model_type,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,model_type,best_parameters_df,X_train_scaled,y_train,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(model_type,X_train_scaled,X_validation_scaled,r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,prediction_type,cv_score,cv_kfold,None)\n",
    "\n",
    "elif prediction_type == 'clas':\n",
    "    # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "    accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,_,_ = predictor_workflow(random_init,model_type,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,model_type,best_parameters_df,X_train_scaled,y_train,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(model_type,X_train_scaled,X_validation_scaled,accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,prediction_type,cv_score,cv_kfold,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the permutation feature importance (PFI) of the descriptors in the \n",
    "# model and generates a new dataset\n",
    "\n",
    "# PFI function\n",
    "combined_descriptor_list = PFI_workflow(X,model_type,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,n_repeats,per_cent_PFI_filter,False,prediction_type,PFI_filtering)\n",
    "\n",
    "# creates X and y sets\n",
    "# creates a database with the most important descriptors after PFI\n",
    "\n",
    "df_PFI_model = pd.DataFrame()\n",
    "df_PFI_model[response_value] = DFT_parameters_filtered[response_value]\n",
    "\n",
    "for i,column in enumerate(DFT_parameters_filtered.columns):\n",
    "    if column in combined_descriptor_list:\n",
    "        df_PFI_model[column] = DFT_parameters_filtered[column]\n",
    "\n",
    "X_PFI = df_PFI_model.drop([response_value], axis=1)\n",
    "y_PFI = df_PFI_model[response_value]\n",
    "\n",
    "# k-neighbours-based data splitting using previous training points\n",
    "X_train_PFI = X_PFI.iloc[training_points]\n",
    "y_train_PFI = y_PFI.iloc[training_points]\n",
    "X_validation_PFI = X_PFI.drop(training_points)\n",
    "y_validation_PFI = y_PFI.drop(training_points)\n",
    "\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean = X_train_PFI.mean(axis=0)\n",
    "Xstd = X_train_PFI.std(axis=0)\n",
    "X_train_PFI_scaled = (X_train_PFI - Xmean) / Xstd\n",
    "X_validation_PFI_scaled = (X_validation_PFI - Xmean) / Xstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the best model from hyperopt and calculates its efficiency using only \n",
    "# the most important features from the PFI analysis\n",
    "if int(best_parameters_df['max_features'][0]) > len(X_PFI.columns):\n",
    "    best_parameters_df.at[0,'max_features'] = len(X_PFI.columns)\n",
    "    # replace the value in the parameters csv\n",
    "    export_param_excel = best_parameters_df.to_csv(name_csv_hyperopt+'.csv', index = None, header=True)\n",
    "\n",
    "if prediction_type == 'reg':\n",
    "    # calculate R2, MAE and RMSE for train and validation sets\n",
    "    r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(random_init,model_type,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,model_type,best_parameters_df,X_train_PFI_scaled,y_train_PFI,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(model_type,X_train_PFI_scaled,X_validation_PFI_scaled,r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,prediction_type,cv_score,cv_kfold,'Robert_results.txt')\n",
    "\n",
    "elif prediction_type == 'clas':\n",
    "    # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "    accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(random_init,model_type,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,model_type,best_parameters_df,X_train_PFI_scaled,y_train_PFI,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(model_type,X_train_PFI_scaled,X_validation_PFI_scaled,accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,prediction_type,cv_score,cv_kfold,'Robert_results.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the permutation feature importance (PFI) of the final model and\n",
    "# saves the data\n",
    "\n",
    "combined_descriptor_list = PFI_workflow(X_PFI,model_type,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,n_repeats,0,True,prediction_type,PFI_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data in a CSV file including set column and predicted values \n",
    "\n",
    "X_train_csv = fixed_data_train.copy()\n",
    "X_validation_csv = fixed_data_validation.copy()\n",
    "\n",
    "X_train_csv[response_value] = y_train_PFI\n",
    "X_validation_csv[response_value] = y_validation_PFI\n",
    "\n",
    "X_train_csv[f'Predicted {response_value}'] = y_pred_train_PFI\n",
    "X_validation_csv[f'Predicted {response_value}'] = y_pred_validation_PFI\n",
    "\n",
    "X_train_csv = pd.concat([X_train_csv, X_train_PFI], axis=1)\n",
    "X_validation_csv = pd.concat([X_validation_csv, X_validation_PFI], axis=1)\n",
    "\n",
    "X_train_csv['Set'] = 'Training'\n",
    "X_validation_csv['Set'] = 'Validation'\n",
    "\n",
    "df_csv = pd.concat([X_train_csv, X_validation_csv], axis=0)\n",
    "\n",
    "# creates an Excel database with only the most important descriptors used by the model\n",
    "export_param_excel = df_csv.to_csv(f'{csv_name}_final_dataset.csv', index = None, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and test sets\n",
    "\n",
    "if prediction_type == 'reg':\n",
    "    sb.set(font_scale=1.2, style=\"ticks\") #set styling preferences\n",
    "\n",
    "    Plotdata_train_PFI = {'y_train_PFI': y_train_PFI, 'y_pred_train_PFI': y_pred_train_PFI} \n",
    "    Plotdata_validation_PFI = {'y_validation_PFI': y_validation_PFI, 'y_pred_validation_PFI': y_pred_validation_PFI}\n",
    "\n",
    "    df_train_PFI = pd.DataFrame.from_dict(Plotdata_train_PFI)\n",
    "    df_validation_PFI = pd.DataFrame.from_dict(Plotdata_validation_PFI)\n",
    "\n",
    "    # Build the plot\n",
    "    # Set up some features to plot the dots\n",
    "    color_train = 'b'\n",
    "    color_validation = 'orange'\n",
    "    size = 30\n",
    "    alpha = 1 # from 0 (transparent) to 1 (opaque)\n",
    "\n",
    "    # Create subplot with a certain size and title\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "    # Set styling preferences\n",
    "    sb.set(font_scale=1.2, style=\"ticks\")\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    # title of the graph\n",
    "    total_points = len(y_train_PFI)+len(y_validation_PFI)\n",
    "    train_proportion = len(y_train_PFI)/total_points\n",
    "    validation_proportion = len(y_validation_PFI)/total_points\n",
    "    ratios =  str(round(train_proportion,2)*100)+':'+str(round(validation_proportion,2)*100)\n",
    "    title_text = model_type+' model with train:validation ('+ratios+') of '+str(total_points)+' datapoints'\n",
    "    \n",
    "    plt.text(0.5, 1.08, title_text, horizontalalignment='center',\n",
    "         fontsize=14, fontweight='bold', transform = ax.transAxes)\n",
    "\n",
    "    # Plot the data\n",
    "    points_train = ax.scatter(df_train_PFI[\"y_train_PFI\"], df_train_PFI[\"y_pred_train_PFI\"],\n",
    "                c = color_train, s = size, edgecolor = 'k', linewidths = 0.8, alpha = alpha, zorder=2)\n",
    "\n",
    "    points_validation = ax.scatter(df_validation_PFI[\"y_validation_PFI\"], df_validation_PFI[\"y_pred_validation_PFI\"],\n",
    "                c = color_validation, s = size, edgecolor = 'k', linewidths = 0.8, alpha = alpha, zorder=2)\n",
    "\n",
    "    # Put a legend below current axis\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.17),\n",
    "            fancybox=True, shadow=True, ncol=5, labels=['Training','Validation'])\n",
    "\n",
    "    # Add the regression line with a confidence interval based on the training sets\n",
    "    plot = sb.regplot(\"y_train_PFI\", \"y_pred_train_PFI\", data=df_train_PFI, scatter=False, color=\".1\", \n",
    "                    truncate = True, ax=ax)\n",
    "\n",
    "    # Title of the axis\n",
    "    plot = ax.set(ylabel=f'Predicted {response_value}', xlabel=f'{response_value} from database')\n",
    "    \n",
    "    # Add gridlines\n",
    "    ax.grid(linestyle='--', linewidth=1)\n",
    "\n",
    "    # set limits\n",
    "    size_space = 0.1*abs(min(y_train_PFI)-max(y_train_PFI))\n",
    "    if min(y_train_PFI) < min(y_validation_PFI):\n",
    "        min_value_graph = min(y_train_PFI)-size_space\n",
    "    else:\n",
    "        min_value_graph = min(y_validation_PFI)-size_space\n",
    "        \n",
    "    if max(y_train_PFI) > max(y_validation_PFI):\n",
    "        max_value_graph = max(y_train_PFI)+size_space\n",
    "    else:\n",
    "        max_value_graph = max(y_validation_PFI)+size_space\n",
    "        \n",
    "    plt.xlim(min_value_graph, max_value_graph)\n",
    "    plt.ylim(min_value_graph, max_value_graph)\n",
    "        \n",
    "    # save the plot a png image, type True\n",
    "    plt.savefig('Predicted vs database values.png', dpi=400, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print('\\nThe corresponding graph was saved in '+w_dir+'.')\n",
    "\n",
    "elif prediction_type == 'clas':\n",
    "    predictor_model = predictor_model_fun(model_type, best_parameters_df, random_init, prediction_type)\n",
    "\n",
    "    predictor_model.fit(X_train_PFI_scaled, y_train_PFI)\n",
    "\n",
    "    plot_confusion_matrix(predictor_model, X_validation_PFI_scaled, y_validation_PFI,cmap='Blues') \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run x- and y-shuffle statistical tests\n",
    "random.seed(a=random_init)\n",
    "\n",
    "# load original data\n",
    "df_tests_model = pd.read_csv(csv_name+'_final_dataset.csv')\n",
    "\n",
    "training_data = df_tests_model[df_tests_model.Set == 'Training']\n",
    "validation_data = df_tests_model[df_tests_model.Set == 'Validation']\n",
    "\n",
    "# parameters to discard from the csv\n",
    "shuffle_drops = fixed_descriptors.copy()\n",
    "shuffle_drops.append('Set')\n",
    "shuffle_drops.append('Predicted '+response_value)\n",
    "\n",
    "X_train_tests = training_data.drop(shuffle_drops, axis=1)\n",
    "X_validation_tests = validation_data.drop(shuffle_drops, axis=1)\n",
    "\n",
    "y_train_tests = training_data[response_value]\n",
    "y_validation_tests = validation_data[response_value]\n",
    "\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean_tests = X_train_tests.mean(axis=0)\n",
    "Xstd_tests = X_train_tests.std(axis=0)\n",
    "X_train_tests_scaled = (X_train_tests - Xmean) / Xstd\n",
    "X_validation_tests_scaled = (X_validation_tests - Xmean) / Xstd\n",
    "\n",
    "y_train_tests = training_data[response_value]\n",
    "y_validation_tests = validation_data[response_value]\n",
    "\n",
    "# x shuffle test\n",
    "X_train_shuffled = training_data.drop(shuffle_drops, axis=1)\n",
    "X_validation_shuffled = validation_data.drop(shuffle_drops, axis=1)\n",
    "\n",
    "# fixed_descriptors\n",
    "X_train_shuffled = np.asarray(X_train_shuffled)\n",
    "X_validation_shuffled = np.asarray(X_validation_shuffled)\n",
    "\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean = X_train_shuffled.mean(axis=0)\n",
    "Xstd = X_train_shuffled.std(axis=0)\n",
    "X_train_shuffled_scaled = (X_train_shuffled - Xmean) / Xstd\n",
    "X_validation_shuffled_scaled = (X_validation_shuffled - Xmean) / Xstd\n",
    "\n",
    "for row in X_train_shuffled_scaled:\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    \n",
    "for row in X_validation_shuffled_scaled:\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "\n",
    "print('\\nResults from the x-shuffle test')\n",
    "r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,y_pred_train_tests,y_pred_validation_tests = predictor_workflow(random_init,model_type,best_parameters_df,X_train_shuffled_scaled,y_train_tests,X_validation_shuffled_scaled,y_validation_tests,prediction_type,training_size)\n",
    "cv_score_x_shuffle = cross_val_calc(random_init,model_type,best_parameters_df,X_train_shuffled_scaled,y_train_tests,prediction_type,cv_kfold)\n",
    "print_model_stats(model_type,X_train_tests_scaled,X_validation_tests_scaled,r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,prediction_type,cv_score_x_shuffle,cv_kfold,'Robert_results_x-shuffle.txt')\n",
    "\n",
    "# y shuffle test\n",
    "y_train_shuffled = y_train_tests.copy()\n",
    "y_validation_shuffled = y_validation_tests.copy()\n",
    "\n",
    "y_train_shuffled = np.asarray(y_train_shuffled)   \n",
    "y_validation_shuffled = np.asarray(y_validation_shuffled) \n",
    "\n",
    "random.shuffle(y_train_shuffled)\n",
    "random.shuffle(y_validation_shuffled)\n",
    "\n",
    "print('\\nResults from the y-shuffle test')\n",
    "r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,y_pred_train_tests,y_pred_validation_tests = predictor_workflow(random_init,model_type,best_parameters_df,X_train_tests_scaled,y_train_shuffled,X_validation_tests_scaled,y_validation_shuffled,prediction_type,training_size)\n",
    "cv_score_y_shuffle = cross_val_calc(random_init,model_type,best_parameters_df,X_train_tests_scaled,y_train_shuffled,prediction_type,cv_kfold)\n",
    "print_model_stats(model_type,X_train_tests_scaled,X_validation_tests_scaled,r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,prediction_type,cv_score_y_shuffle,cv_kfold,'Robert_results_y-shuffle.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "cffebf996e571cf1d75cb986e1cc822ae72f8258874d626c15891ac4551cf4a4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('DL_CPU': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
