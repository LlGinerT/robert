{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import random\n",
    "from Robert_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameters for the workflow\n",
    "\n",
    "# define csv file that contains the database (without the .csv extension) and the response value\n",
    "w_dir = os.getcwd()\n",
    "\n",
    "# name of the csv containing the database without the CSV extension. For example: csv_name = 'Phenolic_data' \n",
    "csv_name = 'Robert_example'\n",
    "\n",
    "# name of the csv file that will contain the optimal parameters\n",
    "name_csv_hyperopt = 'Predictor_parameters'\n",
    "\n",
    "# specify the response value (y), for example: response_value = 'activation_barrier_kcal/mol'\n",
    "response_value = 'Target_values'\n",
    "\n",
    "# specify columns of the csv to drop from the descriptors but to keep in the final database\n",
    "# (i.e. reaction names). For example: fixed_descriptors = ['Name','SMILES','YSI/MW','YSI','CN','MW','weakest_bondtype'].\n",
    "# If there are not descriptors to discard, just use fixed_descriptors = []\n",
    "fixed_descriptors = ['Name']\n",
    "\n",
    "# convert columns with strings into categorical values using 1,2,3... (alternative\n",
    "# to one-hot encoding that the code uses by default)\n",
    "categorical_mode = False\n",
    "\n",
    "# activate with correlation_filter = True\n",
    "correlation_filter = True\n",
    "\n",
    "# threshold values for the correlation filters (if correlation_filter = True)\n",
    "correlation_y_threshold = 0.02 # (only use descriptors that correlate with R**2 > 0.02 with the response value)\n",
    "correlation_x_threshold = 0.85 # (only use descriptors that don't correlate with R**2 > 0.85 with other descriptors)\n",
    "\n",
    "# training set proportion\n",
    "training_size = 80 # relative to the training set proportion (i.e. 40 = 40% training data)\n",
    "\n",
    "# mode for splitting data. Methods available:\n",
    "# 1. k-neighbours clustering-based splitting (KN)\n",
    "# 2. random splitting (RND)\n",
    "split_mode = 'KN'\n",
    "\n",
    "# parameters to be optimized. Different types of regressor models are supported:\n",
    "# 1. Random forests ('RF')\n",
    "# 2. Multivariate lineal models ('MVL')\n",
    "# 3. Gradient boosting ('GB')\n",
    "# 4. AdaBoost regressor ('AdaB')\n",
    "# 5. MLP regressor neural network ('NN')    \n",
    "# 6. Voting regressor combining RF, GB and NN ('VR')\n",
    "model_type = ['RF', 'GB']\n",
    "\n",
    "# type of prediction:\n",
    "# 1. Regressor ('reg')\n",
    "# 2. Classifier ('clas')    \n",
    "prediction_type = 'reg'\n",
    "\n",
    "# random seed used in the ML predictor models\n",
    "random_init = 0\n",
    "\n",
    "# Number of epochs for the hyperopt optimization\n",
    "n_epochs = 100\n",
    "\n",
    "# sets the number of times a feature is randomly shuffled and returns a sample of feature importances (standard from Sklearn webpage: 30)\n",
    "n_repeats = 30\n",
    "\n",
    "# the PFI filter is X% of the model's score (% adjusted with per_cent_PFI_filter, 0.04 = 4%)\n",
    "# WARNING! For regression, a value of 0.04 is recommended. For classification, \n",
    "# a value of 0 is recommended. Turn this option off with PFI_filtering = False\n",
    "PFI_filtering = True\n",
    "if prediction_type == 'reg':\n",
    "    per_cent_PFI_filter = 0.04\n",
    "if prediction_type == 'clas':\n",
    "    per_cent_PFI_filter = 0\n",
    "\n",
    "# number of k-folds for cross validation\n",
    "cv_kfold = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excluded parameters:\n",
      "x1 : R**2 = 1.0 with x3\n",
      "x1 : R**2 = 0.96 with x6\n",
      "x3 : R**2 = 0.95 with x6\n",
      "\n",
      "Successfully created 37 datapoints.\n",
      "\n",
      "\n",
      "Descriptors used after correlation filters:\n",
      "x2\n",
      "x5\n",
      "x6\n",
      "x7\n",
      "x8\n",
      "x9\n",
      "x10\n",
      "x11\n",
      "Csub-Csub\n",
      "Csub-H\n",
      "Csub-O\n",
      "H-O\n"
     ]
    }
   ],
   "source": [
    "# remove correlated variables and noise (variables that do not correlate with the y values)\n",
    "\n",
    "DFT_parameters = pd.read_csv(csv_name+'.csv')\n",
    "\n",
    "# converts all columns with strings into categorical values (one hot encoding\n",
    "# by default, can be set to numerical 1,2,3... with categorical_mode = True).\n",
    "# Troubleshooting! For one-hot encoding, don't use variable names that are\n",
    "# also column headers! 9I.E. DESCRIPTOR \"C_atom\" contain C2 as a value,\n",
    "# but C2 is already a header of a different column in the database. Same applies\n",
    "# for multiple columns containing the same variable names.\n",
    "\n",
    "descriptors_to_drop = []\n",
    "for column in DFT_parameters.columns:\n",
    "    if column not in fixed_descriptors:\n",
    "        if(DFT_parameters[column].dtype == 'object'):\n",
    "            descriptors_to_drop.append(column)\n",
    "            if categorical_mode:\n",
    "                \n",
    "                DFT_parameters[column] = DFT_parameters[column].astype('category')\n",
    "                DFT_parameters[column] = DFT_parameters[column].cat.codes\n",
    "            else:\n",
    "                labels = DFT_parameters[column].unique()\n",
    "                dummies = pd.get_dummies(DFT_parameters[column])\n",
    "                DFT_parameters_filtered = DFT_parameters.drop(column, axis=1)\n",
    "                DFT_parameters = pd.concat([DFT_parameters, dummies], axis=1)\n",
    "\n",
    "if correlation_filter:\n",
    "    descriptors_to_drop = correlation_filter_fun(DFT_parameters,correlation_y_threshold,correlation_x_threshold,fixed_descriptors,descriptors_to_drop,response_value)\n",
    "\n",
    "# this parts allows to drop any descriptor that we don't want to use\n",
    "DFT_parameters_filtered = DFT_parameters.drop(descriptors_to_drop, axis=1)\n",
    "\n",
    "print('\\nSuccessfully created '+ str(len(DFT_parameters[response_value])) + ' datapoints.\\n')\n",
    "print('\\nDescriptors used after correlation filters:')\n",
    "\n",
    "DFT_parameters_filter_print = DFT_parameters_filtered.drop(fixed_descriptors, axis=1)\n",
    "for _,column in enumerate(DFT_parameters_filter_print.columns):\n",
    "    if column != response_value:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate fixed descriptors and create X and y dataframes\n",
    "fixed_data = DFT_parameters_filtered[fixed_descriptors]\n",
    "\n",
    "fixed_descriptors.append(response_value)\n",
    "X = DFT_parameters_filtered.drop(fixed_descriptors, axis=1)\n",
    "y = DFT_parameters_filtered[response_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            x2         x5         x6  x7  x8  x9  x10  x11  Csub-Csub  Csub-H  \\\n",
      "0   110.927040  89.875534  49.772534   1   0   0    0    1          0       1   \n",
      "1   110.655312  78.652351  55.531351   1   0   0    0    1          1       0   \n",
      "2   112.063507  88.850220  13.697220   0   0   1    1    1          0       0   \n",
      "4   111.882454  88.586563   4.543563   1   0   1    1    2          0       0   \n",
      "5   113.064728  89.462921 -30.680079   0   0   2    2    2          0       0   \n",
      "6   110.768921  79.076828   9.545828   1   0   1    1    2          1       0   \n",
      "7   111.555572  78.753319   8.992319   1   0   1    1    2          1       0   \n",
      "9   110.460892  58.436790 -38.724210   0   1   1    2    2          0       0   \n",
      "10  113.922150  69.558273 -27.602727   0   1   1    2    2          0       0   \n",
      "11  112.884415  62.990219 -34.170781   0   1   1    2    2          0       0   \n",
      "15  111.318909  89.782440  41.799440   2   0   0    0    2          0       1   \n",
      "16  110.753632  89.680855  41.867855   2   0   0    0    2          0       1   \n",
      "17  110.959137  78.641785  43.360785   2   0   0    0    2          1       0   \n",
      "18  110.847694  76.107864  10.356864   1   0   0    0    1          1       0   \n",
      "19  111.233978  82.797592   5.392952   2   0   0    0    2          0       1   \n",
      "20  110.370720  78.099075  37.378075   2   0   0    0    2          1       0   \n",
      "22  110.422035  78.395615  37.674615   2   0   0    0    2          1       0   \n",
      "23  110.468247  66.384811   3.963811   1   1   0    1    2          0       0   \n",
      "24  113.392807  69.000313   6.579313   1   1   0    1    2          0       0   \n",
      "25  112.206154  67.169151   4.748151   1   1   0    1    2          0       0   \n",
      "27  111.935509  78.452652 -39.330348   0   0   2    2    2          0       0   \n",
      "28  111.711594  70.306946  17.606946   0   1   0    1    1          0       0   \n",
      "29  111.798355  76.892914 -46.530086   1   0   2    2    3          0       0   \n",
      "30  111.054077  86.167236   3.394236   1   0   1    1    2          0       0   \n",
      "31  110.860184  86.975937   4.932937   1   0   1    1    2          0       0   \n",
      "33  111.030815  84.129349 -69.573651   2   0   1    1    3          0       0   \n",
      "34  111.627693  59.930672 -76.490328   0   2   1    3    3          0       0   \n",
      "35  110.759308  59.814598 -76.606402   0   2   1    3    3          0       0   \n",
      "36  115.229294  70.452332 -65.968668   0   2   1    3    3          0       0   \n",
      "\n",
      "    Csub-O  H-O  \n",
      "0        0    0  \n",
      "1        0    0  \n",
      "2        0    1  \n",
      "4        0    1  \n",
      "5        0    1  \n",
      "6        0    0  \n",
      "7        0    0  \n",
      "9        1    0  \n",
      "10       1    0  \n",
      "11       1    0  \n",
      "15       0    0  \n",
      "16       0    0  \n",
      "17       0    0  \n",
      "18       0    0  \n",
      "19       0    0  \n",
      "20       0    0  \n",
      "22       0    0  \n",
      "23       1    0  \n",
      "24       1    0  \n",
      "25       1    0  \n",
      "27       0    1  \n",
      "28       1    0  \n",
      "29       0    1  \n",
      "30       0    1  \n",
      "31       0    1  \n",
      "33       0    1  \n",
      "34       1    0  \n",
      "35       1    0  \n",
      "36       1    0  \n"
     ]
    }
   ],
   "source": [
    "# data splitting into training and validation sets\n",
    "\n",
    "if split_mode in ['KN','RND']:\n",
    "\n",
    "    X_train, y_train, X_validation, y_validation, training_points = data_split(X,y,training_size,random_init,split_mode)\n",
    "\n",
    "else:\n",
    "    print('x  Select a valid method for splitting data (options: KN, RMD)!')\n",
    "    sys.exit()\n",
    "\n",
    "fixed_data_train = fixed_data.iloc[training_points]\n",
    "fixed_data_validation = fixed_data.drop(training_points)\n",
    "print(X_train)\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean = X_train.mean(axis=0)\n",
    "Xstd = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - Xmean) / Xstd\n",
    "X_validation_scaled = (X_validation - Xmean) / Xstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 17.79trial/s, best loss: 0.12086037009107399]\n",
      "100%|██████████| 100/100 [00:03<00:00, 26.48trial/s, best loss: 0.12330528822327] \n",
      "El mejor modelo es: GB\n"
     ]
    }
   ],
   "source": [
    "if model_type == ['all']:\n",
    "    model_type = ['RF','GB','AdaB','MVL','NN','VR']\n",
    "\n",
    "models_data = []\n",
    "for MODEL in model_type:\n",
    "    models_data_indiv = []\n",
    "    #AQUII\n",
    "    # hyperopt process including k-neighbours-based splitting of the data\n",
    "    hyperopt_process = run_hyperopt(n_epochs, MODEL, X, training_size, prediction_type, random_init, w_dir, X_train_scaled, y_train, X_validation_scaled, y_validation, name_csv_hyperopt)\n",
    "\n",
    "    # read the csv to load and print information about the parameters\n",
    "    best_parameters_df = pd.read_csv(name_csv_hyperopt+'.csv')\n",
    "   \n",
    "    # print information about the hyperopt process\n",
    "    #print_hyperopt_params(MODEL,best_parameters_df,training_size,w_dir)\n",
    "    if prediction_type == 'reg':\n",
    "    # calculate R2, MAE and RMSE for train and validation sets\n",
    "        r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,_,_ = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "        cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "       # print_model_stats(MODEL,X_train_scaled,X_validation_scaled,r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,prediction_type,cv_score,cv_kfold,None)\n",
    "\n",
    "    elif prediction_type == 'clas':\n",
    "    # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "        accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,_,_ = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "        cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "        #print_model_stats(MODEL,X_train_scaled,X_validation_scaled,accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,prediction_type,cv_score,cv_kfold,None)\n",
    "    # calculate the permutation feature importance (PFI) of the descriptors in the \n",
    "    # model and generates a new dataset\n",
    "\n",
    "    # PFI function\n",
    "    combined_descriptor_list = PFI_workflow(X,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,n_repeats,per_cent_PFI_filter,False,prediction_type,PFI_filtering)\n",
    "\n",
    "    # creates X and y sets\n",
    "    # creates a database with the most important descriptors after PFI\n",
    "\n",
    "    df_PFI_model = pd.DataFrame()\n",
    "    df_PFI_model[response_value] = DFT_parameters_filtered[response_value]\n",
    "\n",
    "    for i,column in enumerate(DFT_parameters_filtered.columns):\n",
    "        if column in combined_descriptor_list:\n",
    "            df_PFI_model[column] = DFT_parameters_filtered[column]\n",
    "\n",
    "    X_PFI = df_PFI_model.drop([response_value], axis=1)\n",
    "    y_PFI = df_PFI_model[response_value]\n",
    "\n",
    "    # k-neighbours-based data splitting using previous training points\n",
    "    X_train_PFI = X_PFI.iloc[training_points]\n",
    "    y_train_PFI = y_PFI.iloc[training_points]\n",
    "    X_validation_PFI = X_PFI.drop(training_points)\n",
    "    y_validation_PFI = y_PFI.drop(training_points)\n",
    "\n",
    "    # standardizes the data sets using the mean and standard dev from the train set\n",
    "    Xmean = X_train_PFI.mean(axis=0)\n",
    "    Xstd = X_train_PFI.std(axis=0)\n",
    "    X_train_PFI_scaled = (X_train_PFI - Xmean) / Xstd\n",
    "    X_validation_PFI_scaled = (X_validation_PFI - Xmean) / Xstd\n",
    "    # run the best model from hyperopt and calculates its efficiency using only \n",
    "    # the most important features from the PFI analysis\n",
    "    if int(best_parameters_df['max_features'][0]) > len(X_PFI.columns):\n",
    "        best_parameters_df.at[0,'max_features'] = len(X_PFI.columns)\n",
    "        # replace the value in the parameters csv\n",
    "        export_param_excel = best_parameters_df.to_csv(name_csv_hyperopt+'.csv', index = None, header=True)\n",
    "\n",
    "    if prediction_type == 'reg':\n",
    "        # calculate R2, MAE and RMSE for train and validation sets\n",
    "        r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,prediction_type,training_size)\n",
    "        # calculates k-fold cross validation\n",
    "        cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,prediction_type,cv_kfold)\n",
    "        # print stats\n",
    "        #print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,prediction_type,cv_score,cv_kfold,'Robert_results.txt')\n",
    "        # data of the model\n",
    "        models_data_indiv = [MODEL, best_parameters_df, r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI, cv_score]\n",
    "\n",
    "    elif prediction_type == 'clas':\n",
    "        # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "        accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,prediction_type,training_size)\n",
    "        # calculates k-fold cross validation\n",
    "        cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,prediction_type,cv_kfold)\n",
    "        # print stats\n",
    "        #print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,prediction_type,cv_score,cv_kfold,'Robert_results.txt')\n",
    "         # data of the model\n",
    "        models_data_indiv = [MODEL, best_parameters_df, accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI, cv_score]\n",
    "    \n",
    "    models_data.append(models_data_indiv)\n",
    "\n",
    "    if MODEL==[-1]:\n",
    "        break\n",
    "\n",
    "def minimum(models_data):\n",
    "    min=models_data[0]\n",
    "    for rmse_train_PFI in models_data:\n",
    "        if rmse_train_PFI < min:\n",
    "            min= rmse_train_PFI\n",
    "    return min\n",
    "\n",
    "print(\"El mejor modelo es:\",min[0])\n",
    "    #return \n",
    "    #AQUII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RF\n",
      "k-neighbours-based training, validation and test sets have been created with this distribution:\n",
      "Training points: 29\n",
      "k-neighbours-based training: R2 = 0.99; MAE = 0.06; RMSE = 0.1\n",
      "5-fold cross validation: 0.62 ± 0.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the best model from hyperopt and calculates its efficiency\n",
    "\n",
    "if prediction_type == 'reg':\n",
    "    # calculate R2, MAE and RMSE for train and validation sets\n",
    "    r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,_,_ = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(MODEL,X_train_scaled,X_validation_scaled,r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,prediction_type,cv_score,cv_kfold,None)\n",
    "\n",
    "elif prediction_type == 'clas':\n",
    "    # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "    accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,_,_ = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_scaled,y_train,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(MODEL,X_train_scaled,X_validation_scaled,accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,prediction_type,cv_score,cv_kfold,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the permutation feature importance (PFI) of the descriptors in the \n",
    "# model and generates a new dataset\n",
    "\n",
    "# PFI function\n",
    "combined_descriptor_list = PFI_workflow(X,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,n_repeats,per_cent_PFI_filter,False,prediction_type,PFI_filtering)\n",
    "\n",
    "# creates X and y sets\n",
    "# creates a database with the most important descriptors after PFI\n",
    "\n",
    "df_PFI_model = pd.DataFrame()\n",
    "df_PFI_model[response_value] = DFT_parameters_filtered[response_value]\n",
    "\n",
    "for i,column in enumerate(DFT_parameters_filtered.columns):\n",
    "    if column in combined_descriptor_list:\n",
    "        df_PFI_model[column] = DFT_parameters_filtered[column]\n",
    "\n",
    "X_PFI = df_PFI_model.drop([response_value], axis=1)\n",
    "y_PFI = df_PFI_model[response_value]\n",
    "\n",
    "# k-neighbours-based data splitting using previous training points\n",
    "X_train_PFI = X_PFI.iloc[training_points]\n",
    "y_train_PFI = y_PFI.iloc[training_points]\n",
    "X_validation_PFI = X_PFI.drop(training_points)\n",
    "y_validation_PFI = y_PFI.drop(training_points)\n",
    "\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean = X_train_PFI.mean(axis=0)\n",
    "Xstd = X_train_PFI.std(axis=0)\n",
    "X_train_PFI_scaled = (X_train_PFI - Xmean) / Xstd\n",
    "X_validation_PFI_scaled = (X_validation_PFI - Xmean) / Xstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RF\n",
      "k-neighbours-based training, validation and test sets have been created with this distribution:\n",
      "Training points: 29\n",
      "Validation points: 8\n",
      "\n",
      "k-neighbours-based training: R2 = 0.98; MAE = 0.06; RMSE = 0.09\n",
      "5-fold cross validation: 0.76 ± 0.15\n",
      "k-neighbours-based validation: R2 = 0.97; MAE = 0.1; RMSE = 0.12\n"
     ]
    }
   ],
   "source": [
    "# run the best model from hyperopt and calculates its efficiency using only \n",
    "# the most important features from the PFI analysis\n",
    "if int(best_parameters_df['max_features'][0]) > len(X_PFI.columns):\n",
    "    best_parameters_df.at[0,'max_features'] = len(X_PFI.columns)\n",
    "    # replace the value in the parameters csv\n",
    "    export_param_excel = best_parameters_df.to_csv(name_csv_hyperopt+'.csv', index = None, header=True)\n",
    "\n",
    "if prediction_type == 'reg':\n",
    "    # calculate R2, MAE and RMSE for train and validation sets\n",
    "    r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,prediction_type,cv_score,cv_kfold,'Robert_results.txt')\n",
    "\n",
    "elif prediction_type == 'clas':\n",
    "    # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "    accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,prediction_type,training_size)\n",
    "    # calculates k-fold cross validation\n",
    "    cv_score = cross_val_calc(random_init,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,prediction_type,cv_kfold)\n",
    "    # print stats\n",
    "    print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,prediction_type,cv_score,cv_kfold,'Robert_results.txt')\n",
    "#AQUII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'predictor_model_fun' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [197], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# calculate the permutation feature importance (PFI) of the final model and\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# saves the data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m combined_descriptor_list \u001b[39m=\u001b[39m PFI_workflow(X_PFI,model_type,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,n_repeats,\u001b[39m0\u001b[39m,\u001b[39mTrue\u001b[39;00m,prediction_type,PFI_filtering)\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\robert\\Robert_functions.py:778\u001b[0m, in \u001b[0;36mPFI_workflow\u001b[1;34m(X_PFI_fun, model_type_PFI_fun, best_parameters_df_PFI_fun, X_train_scaled_PFI_fun, y_train_PFI_fun, X_validation_scaled_PFI_fun, y_validation_PFI_fun, n_repeats_PFI_fun, per_cent_PFI_filter_PFI_fun, save_PFI, prediction_type_fun, PFI_filtering)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m X_PFI_fun:\n\u001b[0;32m    776\u001b[0m     combined_descriptor_list\u001b[39m.\u001b[39mappend(column)\n\u001b[1;32m--> 778\u001b[0m model_perm \u001b[39m=\u001b[39m predictor_model_fun(model_type_PFI_fun, best_parameters_df_PFI_fun, \u001b[39m0\u001b[39;49m, prediction_type_fun)\n\u001b[0;32m    780\u001b[0m model_perm\u001b[39m.\u001b[39mfit(X_train_scaled_PFI_fun, y_train_PFI_fun)\n\u001b[0;32m    781\u001b[0m score_model \u001b[39m=\u001b[39m model_perm\u001b[39m.\u001b[39mscore(X_validation_scaled_PFI_fun, y_validation_PFI_fun)\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\robert\\Robert_functions.py:769\u001b[0m, in \u001b[0;36mpredictor_model_fun\u001b[1;34m(model_type_fun, best_parameters_df, random_state, prediction_type_fun)\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMultivariate models (model_type = \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mMVL\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) are not compatible with classifiers (prediction_type = \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mclas\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    767\u001b[0m         sys\u001b[39m.\u001b[39mexit()\n\u001b[1;32m--> 769\u001b[0m \u001b[39mreturn\u001b[39;00m predictor_model_fun\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'predictor_model_fun' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# calculate the permutation feature importance (PFI) of the final model and\n",
    "# saves the data\n",
    "\n",
    "combined_descriptor_list = PFI_workflow(X_PFI,model_type,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,n_repeats,0,True,prediction_type,PFI_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data in a CSV file including set column and predicted values \n",
    "\n",
    "X_train_csv = fixed_data_train.copy()\n",
    "X_validation_csv = fixed_data_validation.copy()\n",
    "\n",
    "X_train_csv[response_value] = y_train_PFI\n",
    "X_validation_csv[response_value] = y_validation_PFI\n",
    "\n",
    "X_train_csv[f'Predicted {response_value}'] = y_pred_train_PFI\n",
    "X_validation_csv[f'Predicted {response_value}'] = y_pred_validation_PFI\n",
    "\n",
    "X_train_csv = pd.concat([X_train_csv, X_train_PFI], axis=1)\n",
    "X_validation_csv = pd.concat([X_validation_csv, X_validation_PFI], axis=1)\n",
    "\n",
    "X_train_csv['Set'] = 'Training'\n",
    "X_validation_csv['Set'] = 'Validation'\n",
    "\n",
    "df_csv = pd.concat([X_train_csv, X_validation_csv], axis=0)\n",
    "\n",
    "# creates an Excel database with only the most important descriptors used by the model\n",
    "export_param_excel = df_csv.to_csv(f'{csv_name}_final_dataset.csv', index = None, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and test sets\n",
    "\n",
    "if prediction_type == 'reg':\n",
    "    sb.set(font_scale=1.2, style=\"ticks\") #set styling preferences\n",
    "\n",
    "    Plotdata_train_PFI = {'y_train_PFI': y_train_PFI, 'y_pred_train_PFI': y_pred_train_PFI} \n",
    "    Plotdata_validation_PFI = {'y_validation_PFI': y_validation_PFI, 'y_pred_validation_PFI': y_pred_validation_PFI}\n",
    "\n",
    "    df_train_PFI = pd.DataFrame.from_dict(Plotdata_train_PFI)\n",
    "    df_validation_PFI = pd.DataFrame.from_dict(Plotdata_validation_PFI)\n",
    "\n",
    "    # Build the plot\n",
    "    # Set up some features to plot the dots\n",
    "    color_train = 'b'\n",
    "    color_validation = 'orange'\n",
    "    size = 30\n",
    "    alpha = 1 # from 0 (transparent) to 1 (opaque)\n",
    "\n",
    "    # Create subplot with a certain size and title\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "    # Set styling preferences\n",
    "    sb.set(font_scale=1.2, style=\"ticks\")\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    # title of the graph\n",
    "    total_points = len(y_train_PFI)+len(y_validation_PFI)\n",
    "    train_proportion = len(y_train_PFI)/total_points\n",
    "    validation_proportion = len(y_validation_PFI)/total_points\n",
    "    ratios =  str(round(train_proportion,2)*100)+':'+str(round(validation_proportion,2)*100)\n",
    "    title_text = model_type+' model with train:validation ('+ratios+') of '+str(total_points)+' datapoints'\n",
    "    \n",
    "    plt.text(0.5, 1.08, title_text, horizontalalignment='center',\n",
    "         fontsize=14, fontweight='bold', transform = ax.transAxes)\n",
    "\n",
    "    # Plot the data\n",
    "    points_train = ax.scatter(df_train_PFI[\"y_train_PFI\"], df_train_PFI[\"y_pred_train_PFI\"],\n",
    "                c = color_train, s = size, edgecolor = 'k', linewidths = 0.8, alpha = alpha, zorder=2)\n",
    "\n",
    "    points_validation = ax.scatter(df_validation_PFI[\"y_validation_PFI\"], df_validation_PFI[\"y_pred_validation_PFI\"],\n",
    "                c = color_validation, s = size, edgecolor = 'k', linewidths = 0.8, alpha = alpha, zorder=2)\n",
    "\n",
    "    # Put a legend below current axis\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.17),\n",
    "            fancybox=True, shadow=True, ncol=5, labels=['Training','Validation'])\n",
    "\n",
    "    # Add the regression line with a confidence interval based on the training sets\n",
    "    plot = sb.regplot(\"y_train_PFI\", \"y_pred_train_PFI\", data=df_train_PFI, scatter=False, color=\".1\", \n",
    "                    truncate = True, ax=ax)\n",
    "\n",
    "    # Title of the axis\n",
    "    plot = ax.set(ylabel=f'Predicted {response_value}', xlabel=f'{response_value} from database')\n",
    "    \n",
    "    # Add gridlines\n",
    "    ax.grid(linestyle='--', linewidth=1)\n",
    "\n",
    "    # set limits\n",
    "    size_space = 0.1*abs(min(y_train_PFI)-max(y_train_PFI))\n",
    "    if min(y_train_PFI) < min(y_validation_PFI):\n",
    "        min_value_graph = min(y_train_PFI)-size_space\n",
    "    else:\n",
    "        min_value_graph = min(y_validation_PFI)-size_space\n",
    "        \n",
    "    if max(y_train_PFI) > max(y_validation_PFI):\n",
    "        max_value_graph = max(y_train_PFI)+size_space\n",
    "    else:\n",
    "        max_value_graph = max(y_validation_PFI)+size_space\n",
    "        \n",
    "    plt.xlim(min_value_graph, max_value_graph)\n",
    "    plt.ylim(min_value_graph, max_value_graph)\n",
    "        \n",
    "    # save the plot a png image, type True\n",
    "    plt.savefig('Predicted vs database values.png', dpi=400, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print('\\nThe corresponding graph was saved in '+w_dir+'.')\n",
    "\n",
    "elif prediction_type == 'clas':\n",
    "    predictor_model = predictor_model_fun(model_type, best_parameters_df, random_init, prediction_type)\n",
    "\n",
    "    predictor_model.fit(X_train_PFI_scaled, y_train_PFI)\n",
    "\n",
    "    plot_confusion_matrix(predictor_model, X_validation_PFI_scaled, y_validation_PFI,cmap='Blues') \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run x- and y-shuffle statistical tests\n",
    "random.seed(a=random_init)\n",
    "\n",
    "# load original data\n",
    "df_tests_model = pd.read_csv(csv_name+'_final_dataset.csv')\n",
    "\n",
    "training_data = df_tests_model[df_tests_model.Set == 'Training']\n",
    "validation_data = df_tests_model[df_tests_model.Set == 'Validation']\n",
    "\n",
    "# parameters to discard from the csv\n",
    "shuffle_drops = fixed_descriptors.copy()\n",
    "shuffle_drops.append('Set')\n",
    "shuffle_drops.append('Predicted '+response_value)\n",
    "\n",
    "X_train_tests = training_data.drop(shuffle_drops, axis=1)\n",
    "X_validation_tests = validation_data.drop(shuffle_drops, axis=1)\n",
    "\n",
    "y_train_tests = training_data[response_value]\n",
    "y_validation_tests = validation_data[response_value]\n",
    "\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean_tests = X_train_tests.mean(axis=0)\n",
    "Xstd_tests = X_train_tests.std(axis=0)\n",
    "X_train_tests_scaled = (X_train_tests - Xmean) / Xstd\n",
    "X_validation_tests_scaled = (X_validation_tests - Xmean) / Xstd\n",
    "\n",
    "y_train_tests = training_data[response_value]\n",
    "y_validation_tests = validation_data[response_value]\n",
    "\n",
    "# x shuffle test\n",
    "X_train_shuffled = training_data.drop(shuffle_drops, axis=1)\n",
    "X_validation_shuffled = validation_data.drop(shuffle_drops, axis=1)\n",
    "\n",
    "# fixed_descriptors\n",
    "X_train_shuffled = np.asarray(X_train_shuffled)\n",
    "X_validation_shuffled = np.asarray(X_validation_shuffled)\n",
    "\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean = X_train_shuffled.mean(axis=0)\n",
    "Xstd = X_train_shuffled.std(axis=0)\n",
    "X_train_shuffled_scaled = (X_train_shuffled - Xmean) / Xstd\n",
    "X_validation_shuffled_scaled = (X_validation_shuffled - Xmean) / Xstd\n",
    "\n",
    "for row in X_train_shuffled_scaled:\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    \n",
    "for row in X_validation_shuffled_scaled:\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "\n",
    "print('\\nResults from the x-shuffle test')\n",
    "r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,y_pred_train_tests,y_pred_validation_tests = predictor_workflow(random_init,model_type,best_parameters_df,X_train_shuffled_scaled,y_train_tests,X_validation_shuffled_scaled,y_validation_tests,prediction_type,training_size)\n",
    "cv_score_x_shuffle = cross_val_calc(random_init,model_type,best_parameters_df,X_train_shuffled_scaled,y_train_tests,prediction_type,cv_kfold)\n",
    "print_model_stats(model_type,X_train_tests_scaled,X_validation_tests_scaled,r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,prediction_type,cv_score_x_shuffle,cv_kfold,'Robert_results_x-shuffle.txt')\n",
    "\n",
    "# y shuffle test\n",
    "y_train_shuffled = y_train_tests.copy()\n",
    "y_validation_shuffled = y_validation_tests.copy()\n",
    "\n",
    "y_train_shuffled = np.asarray(y_train_shuffled)   \n",
    "y_validation_shuffled = np.asarray(y_validation_shuffled) \n",
    "\n",
    "random.shuffle(y_train_shuffled)\n",
    "random.shuffle(y_validation_shuffled)\n",
    "\n",
    "print('\\nResults from the y-shuffle test')\n",
    "r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,y_pred_train_tests,y_pred_validation_tests = predictor_workflow(random_init,model_type,best_parameters_df,X_train_tests_scaled,y_train_shuffled,X_validation_tests_scaled,y_validation_shuffled,prediction_type,training_size)\n",
    "cv_score_y_shuffle = cross_val_calc(random_init,model_type,best_parameters_df,X_train_tests_scaled,y_train_shuffled,prediction_type,cv_kfold)\n",
    "print_model_stats(model_type,X_train_tests_scaled,X_validation_tests_scaled,r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,prediction_type,cv_score_y_shuffle,cv_kfold,'Robert_results_y-shuffle.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c5487727bc19a7756b0b46e65906cd028f983eb1d2958fa31410245bab4c89c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
