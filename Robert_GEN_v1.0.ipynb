{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import csv\n",
    "import shutil\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mcolor\n",
    "import random\n",
    "import matplotlib.patches as mpatches\n",
    "from Robert_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general parameters for the workflow\n",
    "\n",
    "\n",
    "# number of k-folds for cross validation\n",
    "cv_kfold = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Excluded parameters:\n",
      "x1 : R**2 = 1.0 with x3\n",
      "x1 : R**2 = 0.96 with x6\n",
      "x3 : R**2 = 0.95 with x6\n",
      "\n",
      "Successfully created 37 datapoints.\n",
      "\n",
      "\n",
      "Descriptors used after correlation filters:\n",
      "x2\n",
      "x5\n",
      "x6\n",
      "x7\n",
      "x8\n",
      "x9\n",
      "x10\n",
      "x11\n",
      "Csub-Csub\n",
      "Csub-H\n",
      "Csub-O\n",
      "H-O\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate fixed descriptors and create X and y dataframes\n",
    "fixed_data = DFT_parameters_filtered[fixed_descriptors]\n",
    "\n",
    "fixed_descriptors.append(response_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 13.33trial/s, best loss: 0.2222170828214671]\n",
      "100%|██████████| 5/5 [00:00<00:00, 11.03trial/s, best loss: 0.1996192977283523] \n",
      "100%|██████████| 5/5 [00:00<00:00, 23.84trial/s, best loss: 0.129822432847353]  \n",
      "100%|██████████| 5/5 [00:00<00:00, 12.26trial/s, best loss: 0.12330528822327]   \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'rmse_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 208\u001b[0m\n\u001b[0;32m    206\u001b[0m csv_files \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39mRaw_data/Model_params/*[!_PFI]*.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    207\u001b[0m column_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrmse_validation\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 208\u001b[0m min_value, min_file \u001b[39m=\u001b[39m find_min_column_value(csv_files, column_name, \u001b[39m'\u001b[39m\u001b[39mRaw_data/Best_Model/Best_Model.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    210\u001b[0m csv_files_PFI \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39mRaw_data/Model_params/*_PFI*.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    211\u001b[0m column_name_PFI \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrmse_validation_PFI\u001b[39m\u001b[39m'\u001b[39m\n",
      "Cell \u001b[1;32mIn [32], line 198\u001b[0m, in \u001b[0;36mfind_min_column_value\u001b[1;34m(csv_files, column_name, output_directory)\u001b[0m\n\u001b[0;32m    196\u001b[0m reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mDictReader(f)\n\u001b[0;32m    197\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m reader:\n\u001b[1;32m--> 198\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(row[column_name])\n\u001b[0;32m    199\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39m<\u001b[39m min_value:\n\u001b[0;32m    200\u001b[0m         min_value \u001b[39m=\u001b[39m value\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rmse_validation'"
     ]
    }
   ],
   "source": [
    "# Check if the folders exist and if they do, delete them and replace them with new ones.\n",
    "folder_names = ['Benchmark_methods', 'Raw_data/Best_Model', 'Raw_data/Model_params']\n",
    "\n",
    "for folder in folder_names:\n",
    "    try:\n",
    "        # Si la carpeta existe, se elimina\n",
    "        if os.path.exists(folder):\n",
    "            shutil.rmtree(folder)\n",
    "        # Si no existe, se crea\n",
    "        os.makedirs(folder)\n",
    "    except Exception as e:\n",
    "        # Si se produce algún error, se imprime un mensaje\n",
    "        print(f'Error while deleting/creating folder \"{folder}\": {e}')\n",
    "\n",
    "from Robert_functions import *\n",
    "def train_and_evaluate_models(X, y, train, split, model, mode, seed, w_dir, csv_params, cv_kfold):\n",
    "    if train == ['all']:\n",
    "        train = [90,80,70,60,50,40,30,20,10]\n",
    "\n",
    "    size_data= [ ]\n",
    "    for size in train:\n",
    "        size_data_indiv = []\n",
    "            \n",
    "        if split in ['KN','RND']:\n",
    "\n",
    "            X_train, y_train, X_validation, y_validation, training_points = data_split(X,y,size,seed,split)\n",
    "        else:\n",
    "            print('x  Select a valid method for splitting data (options: KN, RMD)!')\n",
    "            sys.exit()\n",
    "\n",
    "        fixed_data_train = fixed_data.iloc[training_points]\n",
    "        fixed_data_validation = fixed_data.drop(training_points)\n",
    "        #print(X_train)\n",
    "        # standardizes the data sets using the mean and standard dev from the train set\n",
    "        Xmean = X_train.mean(axis=0)\n",
    "        Xstd = X_train.std(axis=0)\n",
    "        X_train_scaled = (X_train - Xmean) / Xstd\n",
    "        X_validation_scaled = (X_validation - Xmean) / Xstd\n",
    "        if model == ['all']:\n",
    "            model = ['RF','GB','AdaB','MVL','NN','VR']\n",
    "            \n",
    "        models_data = []\n",
    "        for MODEL in model:\n",
    "            models_data_indiv = []\n",
    "            # hyperopt process including k-neighbours-based splitting of the data\n",
    "            hyperopt_process = run_hyperopt(epochs, MODEL, X, size, mode, seed, w_dir, X_train_scaled, y_train, X_validation_scaled, y_validation, csv_params)\n",
    "\n",
    "            # read the csv to load and print information about the parameters\n",
    "            best_parameters_df = pd.read_csv(csv_params+'.csv')\n",
    "        \n",
    "            # print information about the hyperopt process\n",
    "            #print_hyperopt_params(MODEL,best_parameters_df,train,w_dir)\n",
    "            if mode == 'reg':\n",
    "            # calculate R2, MAE and RMSE for train and validation sets\n",
    "                r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,_,_ = predictor_workflow(seed,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,mode,size)\n",
    "            # calculates k-fold cross validation\n",
    "                cv_score = cross_val_calc(seed,MODEL,best_parameters_df,X_train_scaled,y_train,mode,cv_kfold)\n",
    "            # print stats\n",
    "            # print_model_stats(MODEL,X_train_scaled,X_validation_scaled,r2_train,mae_train,rmse_train,r2_validation,mae_validation,rmse_validation,mode,cv_score,cv_kfold,None)\n",
    "\n",
    "            elif mode == 'clas':\n",
    "            # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "                accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,_,_ = predictor_workflow(seed,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,mode,size)\n",
    "            # calculates k-fold cross validation\n",
    "                cv_score = cross_val_calc(seed,MODEL,best_parameters_df,X_train_scaled,y_train,mode,cv_kfold)\n",
    "            # print stats\n",
    "                #print_model_stats(MODEL,X_train_scaled,X_validation_scaled,accuracy_train,f1score_train,mcc_train,accuracy_validation,f1score_validation,mcc_validation,mode,cv_score,cv_kfold,None)\n",
    "        \n",
    "        # calculate the permutation feature importance (PFI) of the descriptors in the \n",
    "            # model and generates a new dataset\n",
    "            # print(rmse_validation)\n",
    "            dict_model = {\n",
    "                            \"MODEL\": MODEL,\n",
    "                            \"size\": size,\n",
    "                            \"best_parameters_df\": best_parameters_df,\n",
    "                            \"r2_train\": r2_train,\n",
    "                            \"mae_train\": mae_train,\n",
    "                            \"rmse_train\": rmse_train,\n",
    "                            \"r2_validation\": r2_validation,\n",
    "                            \"mae_validation\": mae_validation,\n",
    "                            \"rmse_validation\": rmse_validation,\n",
    "                            \"X_validation_scaled\": X_validation_scaled,\n",
    "                            \"X_train_scaled\": X_train_scaled,\n",
    "                            \"cv_score\": cv_score,\n",
    "                            \"X_validation\": X_validation,\n",
    "                            \"mode\": mode,\n",
    "                            \"cv_kfold\": cv_kfold,\n",
    "                            \"Robert_results\": \"Robert_results.txt\",\n",
    "                            \"y_train\": y_train,\n",
    "                            \"y_validation\": y_validation,\n",
    "                            \"X\": X,\n",
    "                            \"fixed_data_train\": fixed_data_train,\n",
    "                            \"fixed_data_validation\": fixed_data_validation\n",
    "                        }\n",
    "            dict_model_pd = pd.DataFrame.from_dict(dict_model, orient='index')\n",
    "            dict_model_pd=dict_model_pd.transpose()\n",
    "            dict_model_excel = dict_model_pd.to_csv(f'Raw_data/Model_params/{dict_model[\"MODEL\"]}_{size}.csv', index = None, header=True)\n",
    "        \n",
    "            # PFI function\n",
    "            combined_descriptor_list = PFI_workflow(X,MODEL,best_parameters_df,X_train_scaled,y_train,X_validation_scaled,y_validation,n_repeats,PFI_threshold,False,mode,PFI)\n",
    "\n",
    "            # creates X and y sets\n",
    "            # creates a database with the most important descriptors after PFI\n",
    "\n",
    "            df_PFI_model = pd.DataFrame()\n",
    "            df_PFI_model[response_value] = DFT_parameters_filtered[response_value]\n",
    "\n",
    "            for i,column in enumerate(DFT_parameters_filtered.columns):\n",
    "                if column in combined_descriptor_list:\n",
    "                    df_PFI_model[column] = DFT_parameters_filtered[column]\n",
    "\n",
    "            X_PFI = df_PFI_model.drop([response_value], axis=1)\n",
    "            y_PFI = df_PFI_model[response_value]\n",
    "\n",
    "            # k-neighbours-based data splitting using previous training points\n",
    "            X_train_PFI = X_PFI.iloc[training_points]\n",
    "            y_train_PFI = y_PFI.iloc[training_points]\n",
    "            X_validation_PFI = X_PFI.drop(training_points)\n",
    "            y_validation_PFI = y_PFI.drop(training_points)\n",
    "\n",
    "            # standardizes the data sets using the mean and standard dev from the train set\n",
    "            Xmean = X_train_PFI.mean(axis=0)\n",
    "            Xstd = X_train_PFI.std(axis=0)\n",
    "            X_train_PFI_scaled = (X_train_PFI - Xmean) / Xstd\n",
    "            X_validation_PFI_scaled = (X_validation_PFI - Xmean) / Xstd\n",
    "            # run the best model from hyperopt and calculates its efficiency using only \n",
    "            # the most important features from the PFI analysis\n",
    "            try:\n",
    "                if int(best_parameters_df['max_features'][0]) > len(X_PFI.columns):\n",
    "                    best_parameters_df.at[0,'max_features'] = len(X_PFI.columns)\n",
    "                    # replace the value in the parameters csv\n",
    "                    export_param_excel = best_parameters_df.to_csv(csv_params+'.csv', index = None, header=True)\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "            if mode == 'reg':\n",
    "                # calculate R2, MAE and RMSE for train and validation sets\n",
    "                r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(seed,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,mode,size)\n",
    "                # calculates k-fold cross validation\n",
    "                cv_score = cross_val_calc(seed,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,mode,cv_kfold)\n",
    "                # print stats\n",
    "                #print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,mode,cv_score,cv_kfold,'Robert_results.txt')\n",
    "                # data of the model\n",
    "                dict_model_PFI = {\n",
    "                    \"MODEL\": MODEL,\n",
    "                    \"size\": size,\n",
    "                    \"best_parameters_df\": best_parameters_df,\n",
    "                    \"r2_train_PFI\": r2_train_PFI,\n",
    "                    \"mae_train_PFI\": mae_train_PFI,\n",
    "                    \"rmse_train_PFI\": rmse_train_PFI,\n",
    "                    \"r2_validation_PFI\": r2_validation_PFI,\n",
    "                    \"mae_validation_PFI\": mae_validation_PFI,\n",
    "                    \"rmse_validation_PFI\": rmse_validation_PFI,\n",
    "                    \"rmse_validation\": rmse_validation,\n",
    "                    \"X_train_PFI_scaled\": X_train_PFI_scaled,\n",
    "                    \"X_train_scaled\": X_train_scaled,\n",
    "                    \"y_pred_train_PFI\": y_pred_train_PFI,\n",
    "                    \"y_pred_validation_PFI\": y_pred_validation_PFI,\n",
    "                    \"cv_score\": cv_score,\n",
    "                    \"X_validation_PFI_scaled\": X_validation_PFI_scaled,\n",
    "                    \"mode\": mode,\n",
    "                    \"cv_kfold\": cv_kfold,\n",
    "                    \"Robert_results\": \"Robert_results.txt\",\n",
    "                    \"y_train_PFI\": y_train_PFI,\n",
    "                    \"y_validation_PFI\": y_validation_PFI,\n",
    "                    \"X_PFI\": X_PFI,\n",
    "                    \"fixed_data_train\": fixed_data_train,\n",
    "                    \"fixed_data_validation\": fixed_data_validation\n",
    "                }\n",
    "                models_data_indiv = [MODEL, best_parameters_df, r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,rmse_validation,X_train_PFI_scaled,X_train_scaled,y_pred_train_PFI,y_pred_validation_PFI, cv_score,X_validation_PFI_scaled,mode,cv_kfold,'Robert_results.txt',y_train_PFI,y_validation_PFI, X_PFI,fixed_data_train,fixed_data_validation]\n",
    "            elif mode == 'clas':\n",
    "                # calculate accuracy, F1 score and MCC for train and validation sets\n",
    "                accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI = predictor_workflow(seed,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,mode,size)\n",
    "                # calculates k-fold cross validation\n",
    "                cv_score = cross_val_calc(seed,MODEL,best_parameters_df,X_train_PFI_scaled,y_train_PFI,mode,cv_kfold)\n",
    "                # print stats\n",
    "                #print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,mode,cv_score,cv_kfold,'Robert_results.txt')\n",
    "                # data of the model\n",
    "                models_data_indiv = [MODEL, best_parameters_df, accuracy_train_PFI,f1score_train_PFI,mcc_train_PFI,accuracy_validation_PFI,f1score_validation_PFI,mcc_validation_PFI,y_pred_train_PFI,y_pred_validation_PFI, cv_score]\n",
    "        \n",
    "            #Create csv files for all model and training sizes\n",
    "            dict_model_PFI_pd = pd.DataFrame.from_dict(dict_model_PFI, orient='index')\n",
    "            dict_model_PFI_pd=dict_model_PFI_pd.transpose()\n",
    "            dict_model_PFI_excel = dict_model_PFI_pd.to_csv(f'Raw_data/Model_params/{dict_model_PFI[\"MODEL\"]}_{size}_PFI.csv', index = None, header=True)\n",
    "\n",
    "            models_data.append(models_data_indiv)\n",
    "    \n",
    "        size_data_indiv = [size,models_data]\n",
    "        size_data.append(size_data_indiv)\n",
    "        \n",
    "train_and_evaluate_models(X, y, train, split, model, mode, seed, w_dir, csv_params, cv_kfold)\n",
    "def find_min_column_value(csv_files, column_name, output_directory):\n",
    "    min_value = float('inf')\n",
    "    min_file = None\n",
    "    for csv_file in csv_files:\n",
    "        with open(csv_file, 'r') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                value = float(row[column_name])\n",
    "                if value < min_value:\n",
    "                    min_value = value\n",
    "                    min_file = csv_file\n",
    "    \n",
    "    shutil.copy(min_file, output_directory)\n",
    "    return min_value, min_file\n",
    "\n",
    "csv_files = glob.glob('Raw_data/Model_params/*[!_PFI]*.csv')\n",
    "column_name = 'rmse_validation'\n",
    "min_value, min_file = find_min_column_value(csv_files, column_name, 'Raw_data/Best_Model/Best_Model.csv')\n",
    "\n",
    "csv_files_PFI = glob.glob('Raw_data/Model_params/*_PFI*.csv')\n",
    "column_name_PFI = 'rmse_validation_PFI'\n",
    "min_value_PFI, min_file_PFI = find_min_column_value(csv_files_PFI, column_name_PFI, 'Raw_data/Best_Model/Best_Model_PFI.csv')\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df_min = pd.read_csv(min_file)\n",
    "\n",
    "# Get the 'MODEL' and 'size' values from the first row of the DataFrame\n",
    "model_value = df_min['MODEL'].iloc[0]\n",
    "size_value = df_min['size'].iloc[0]\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df_min_PFI = pd.read_csv(min_file_PFI)\n",
    "\n",
    "# Get the 'MODEL' and 'size' values from the first row of the DataFrame\n",
    "model_value_PFI = df_min_PFI['MODEL'].iloc[0]\n",
    "size_value_PFI = df_min_PFI['size'].iloc[0]\n",
    "\n",
    "# Warning if there is a model without PFI with rmse < than model with PFI with the less rmse value  \n",
    "if min_value < min_value_PFI:\n",
    "    print('\\n'f\"x  Warning! Error lower without PFI filter (no PFI: RMSE = {round(min_value,2)} using {model_value}_{size_value} ; with PFI filter: {round(min_value_PFI,2)} using {model_value_PFI}_{size_value_PFI}) consider using PFI=False\")      \n",
    "\n",
    "print('\\n'f\"The optimal model using PFI={PFI} is {model_value_PFI} with training size {size_value_PFI}%\"'\\n')\n",
    "\n",
    "#Obtain the best model (<rmse_validation value)\n",
    "#best_model = optimal_model(size_data)\n",
    "\n",
    "# List to store the rmse_validation_PFI values of files without _PFI in the name\n",
    "rmse_list_1 = []\n",
    "# List to store the rmse_validation_PFI values of the files with _PFI in the name\n",
    "rmse_list_2 = []\n",
    "# Iterate over the csv files in the directory Raw_data/Model_params\n",
    "for filename in os.listdir(\"Raw_data/Model_params\"):\n",
    "    # If the file does not have _PFI in its name\n",
    "    if \"_PFI\" not in filename:\n",
    "        # Read the file with pandas and select the value of rmse_validation_PFI\n",
    "        df = pd.read_csv(f\"Raw_data/Model_params/{filename}\")\n",
    "        rmse = df[\"rmse_validation\"].values[0]\n",
    "        # Add the value to the list rmse_list_1\n",
    "        rmse_list_1.append(rmse)\n",
    "    # If the file does have _PFI in its name\n",
    "    else:\n",
    "        # Read the file with pandas and select the value of rmse_validation_PFI\n",
    "        df = pd.read_csv(f\"Raw_data/Model_params/{filename}\")\n",
    "        rmse = df[\"rmse_validation_PFI\"].values[0]\n",
    "        # Add the value to the list rmse_list_2\n",
    "        rmse_list_2.append(rmse)\n",
    "\n",
    "def create_dataframe(data, column_name):\n",
    "    num_columns = len(model)\n",
    "    num_rows = len(train)\n",
    "    # Creates a list of column names using model\n",
    "    column_names = sorted(model)\n",
    "    # Creates a list of row names using train\n",
    "    row_names = train\n",
    "    values_matrix = np.array(data).reshape(num_columns, num_rows)\n",
    "    # Creates the DataFrame using pd.DataFrame() and providing the array of values, the number of columns and rows, and the lists of column and row names\n",
    "    df = pd.DataFrame(data=values_matrix, columns=row_names, index=column_names)\n",
    "    df = df.transpose()\n",
    "    df.columns.name = column_name\n",
    "    return df\n",
    "plot_data_1 = create_dataframe(rmse_list_1, 'Model Type')\n",
    "plot_data_2 = create_dataframe(rmse_list_2, 'Model Type')\n",
    "\n",
    "def create_heatmap(data, title, output_file):\n",
    "    df_plot = pd.DataFrame(data)\n",
    "    df_plot.columns = [model]\n",
    "    df_plot.index = [train]\n",
    "    df_plot = df_plot.sort_index(ascending=False)\n",
    "    fig, ax = plt.subplots(figsize=(7.45,6))\n",
    "    sb.set(font_scale=1.2, style='ticks')\n",
    "    cmap_blues_75_percent_512 =  [mcolor.rgb2hex(c) for c in plt.cm.Blues(np.linspace(0, 0.8, 512))]\n",
    "    ax = sb.heatmap(df_plot, annot=True, linewidth=1, cmap=cmap_blues_75_percent_512, cbar_kws={'label': 'RMSE Validation'})\n",
    "    ax.set(xlabel=\"Model Type\", ylabel=\"Training Size\")\n",
    "    plt.title(title)\n",
    "    sb.despine(top=False, right=False)\n",
    "    plt.savefig(output_file, dpi=600, bbox_inches='tight')\n",
    "    ax.plot()\n",
    "\n",
    "if PFI:\n",
    "    create_heatmap(plot_data_1, 'NO_PFI', 'Benchmark_methods/NO_PFI.png')\n",
    "    create_heatmap(plot_data_2, 'PFI', 'Benchmark_methods/PFI.png')\n",
    "else:\n",
    "    create_heatmap(plot_data_1, 'NO_PFI', 'Benchmark_methods/NO_PFI.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x6        x7       x10\n",
      "3   0.560956 -1.115352 -0.093580\n",
      "7   0.330019  0.176108 -0.093580\n",
      "8   0.323469  0.176108 -0.093580\n",
      "11 -0.771414 -1.115352  0.935804\n",
      "13  1.193091  1.467569 -1.122965\n",
      "14  1.179330  1.467569 -1.122965\n",
      "15  1.167189  1.467569 -1.122965\n",
      "17  1.207031  1.467569 -1.122965\n",
      "21  1.068913  1.467569 -1.122965\n",
      "22  1.061932  1.467569 -1.122965\n",
      "25  0.221717  0.176108 -0.093580\n",
      "26  1.402781  0.176108 -1.122965\n",
      "31  0.226432  0.176108 -0.093580\n",
      "34 -1.851322 -1.115352  1.965189\n",
      "35 -1.854284 -1.115352  1.965189\n",
      "[0.90748125 0.82181002 0.5219487  0.28883196 0.71309385]\n",
      "Model: RF\n",
      "k-neighbours-based training, validation and test sets have been created with this distribution:\n",
      "Training points: 758\n",
      "Validation points: 527\n",
      "\n",
      "k-neighbours-based training: R2 = 0.97; MAE = 0.08; RMSE = 0.12\n",
      "5.0-fold cross validation: 0.65 ± 0.22\n",
      "k-neighbours-based validation: R2 = 0.96; MAE = 0.11; RMSE = 0.16\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 52\u001b[0m\n\u001b[0;32m     42\u001b[0m print_model_stats(df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mMODEL\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m], df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mX_train_PFI_scaled\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m], df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mX_validation_PFI_scaled\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m],\n\u001b[0;32m     43\u001b[0m                   \u001b[39mfloat\u001b[39m(df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mr2_train_PFI\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]), \u001b[39mfloat\u001b[39m(df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mmae_train_PFI\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]), \u001b[39mfloat\u001b[39m(df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mrmse_train_PFI\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]),\n\u001b[0;32m     44\u001b[0m                   \u001b[39mfloat\u001b[39m(df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mr2_validation_PFI\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]), \u001b[39mfloat\u001b[39m(df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mmae_validation_PFI\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]), \u001b[39mfloat\u001b[39m(df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mrmse_validation_PFI\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]),\n\u001b[0;32m     45\u001b[0m                   df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mprediction_type\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m], np\u001b[39m.\u001b[39masarray(cv_score), \u001b[39mfloat\u001b[39m(df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mcv_kfold\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]), df_model_PFI[\u001b[39m\"\u001b[39m\u001b[39mRobert_results\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[0;32m     47\u001b[0m \u001b[39m#print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,prediction_type,cv_score,cv_kfold,'Robert_results.txt')\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39m# calculate the permutation feature importance (PFI) of the final model and saves the data\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39m# models_data_indiv = [MODEL, best_parameters_df, r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,rmse_validation,X_train_PFI_scaled,X_train_scaled,y_pred_train_PFI,y_pred_validation_PFI, cv_score,X_validation_PFI_scaled,prediction_type,cv_kfold,'Robert_results.txt',y_train_PFI,y_validation_PFI]\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m# combined_descriptor_list = PFI_workflow(X_PFI,model_type,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,n_repeats,0,True,prediction_type,PFI_filtering)\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m combined_descriptor_list \u001b[39m=\u001b[39m PFI_workflow(best_model[\u001b[39m20\u001b[39m],best_model[\u001b[39m0\u001b[39m],best_model[\u001b[39m1\u001b[39m],best_model[\u001b[39m9\u001b[39m],best_model[\u001b[39m18\u001b[39m],best_model[\u001b[39m14\u001b[39m],best_model[\u001b[39m19\u001b[39m],n_repeats,\u001b[39m0\u001b[39m,\u001b[39mTrue\u001b[39;00m,prediction_type,PFI_filtering)\n\u001b[0;32m     54\u001b[0m \u001b[39m#Save the data in a CSV file including set column and predicted values \u001b[39;00m\n\u001b[0;32m     56\u001b[0m X_train_csv \u001b[39m=\u001b[39m best_model[\u001b[39m21\u001b[39m]\u001b[39m.\u001b[39mcopy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# with open(min_file_PFI, 'r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     data = list(reader)\n",
    "\n",
    "df_model_PFI = pd.read_csv(min_file_PFI)\n",
    "# print(df_model_PFI)\n",
    "#Dictionary with the values of the best model_PFI\n",
    "# dict_model_PFI = {\n",
    "#         \"MODEL\": data[1][0],\n",
    "#         \"size\": data[1][1],\n",
    "#         \"best_parameters_df\": data[1][2],\n",
    "#         \"r2_train_PFI\": data[1][3],\n",
    "#         \"mae_train_PFI\": data[1][4],\n",
    "#         \"rmse_train_PFI\": data[1][5],\n",
    "#         \"r2_validation_PFI\": data[1][6],\n",
    "#         \"mae_validation_PFI\": data[1][7],\n",
    "#         \"rmse_validation_PFI\": data[1][8],\n",
    "#         \"rmse_validation\": data[1][9],\n",
    "#         \"X_train_PFI_scaled\": data[1][10],\n",
    "#         \"X_train_scaled\": data[1][11],\n",
    "#         \"y_pred_train_PFI\": data[1][12],\n",
    "#         \"y_pred_validation_PFI\": data[1][13],\n",
    "#         \"cv_score\": data[1][14],\n",
    "#         \"X_validation_PFI_scaled\": data[1][15],\n",
    "#         \"mode\": data[1][16],\n",
    "#         \"cv_kfold\": data[1][17],\n",
    "#         \"Robert_results\": data[1][18],\n",
    "#         \"y_train_PFI\": data[1][19],\n",
    "#         \"y_validation_PFI\": data[1][20],\n",
    "#         \"X_PFI\": data[1][21],\n",
    "#         \"fixed_data_train\": data[1][22],\n",
    "#         \"fixed_data_validation\": data[1][23]\n",
    "# }\n",
    "# # run the best model from hyperopt and calculates its efficiency using only the most important features from the PFI analysis\n",
    "# print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,mode,cv_score,cv_kfold,'Robert_results.txt')\n",
    "\n",
    "dict_model_PFI = {}\n",
    "\n",
    "cv_score = df_model_PFI[\"cv_score\"][0].replace('[','').replace(']','')\n",
    "dict_model_PFI['cv_score'] = [float(x) for x in cv_score.split()]\n",
    "\n",
    "print(df_model_PFI[\"X_validation_PFI_scaled\"][0])\n",
    "print(np.asarray(df_model_PFI[\"cv_score\"][0]))\n",
    "# print_model_stats(best_model[0],best_model[9],best_model[14],best_model[2],best_model[3],best_model[4],best_model[5],best_model[6],best_model[7],mode,best_model[13],best_model[16],best_model[17])\n",
    "print_model_stats(df_model_PFI[\"MODEL\"][0], df_model_PFI[\"X_train_PFI_scaled\"][0], df_model_PFI[\"X_validation_PFI_scaled\"][0],\n",
    "                  float(df_model_PFI[\"r2_train_PFI\"][0]), float(df_model_PFI[\"mae_train_PFI\"][0]), float(df_model_PFI[\"rmse_train_PFI\"][0]),\n",
    "                  float(df_model_PFI[\"r2_validation_PFI\"][0]), float(df_model_PFI[\"mae_validation_PFI\"][0]), float(df_model_PFI[\"rmse_validation_PFI\"][0]),\n",
    "                  df_model_PFI[\"mode\"][0], np.asarray(cv_score), int(df_model_PFI[\"cv_kfold\"][0]), df_model_PFI[\"Robert_results\"][0])\n",
    "\n",
    "#print_model_stats(MODEL,X_train_PFI_scaled,X_validation_PFI_scaled,r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,mode,cv_score,cv_kfold,'Robert_results.txt')\n",
    "# calculate the permutation feature importance (PFI) of the final model and saves the data\n",
    "# models_data_indiv = [MODEL, best_parameters_df, r2_train_PFI,mae_train_PFI,rmse_train_PFI,r2_validation_PFI,mae_validation_PFI,rmse_validation_PFI,rmse_validation,X_train_PFI_scaled,X_train_scaled,y_pred_train_PFI,y_pred_validation_PFI, cv_score,X_validation_PFI_scaled,mode,cv_kfold,'Robert_results.txt',y_train_PFI,y_validation_PFI]\n",
    "# combined_descriptor_list = PFI_workflow(X_PFI,model,best_parameters_df,X_train_PFI_scaled,y_train_PFI,X_validation_PFI_scaled,y_validation_PFI,n_repeats,0,True,mode,PFI)\n",
    "\n",
    "combined_descriptor_list = PFI_workflow(best_model[20],best_model[0],best_model[1],best_model[9],best_model[18],best_model[14],best_model[19],n_repeats,0,True,mode,PFI)\n",
    "\n",
    "#Save the data in a CSV file including set column and predicted values \n",
    "\n",
    "X_train_csv = best_model[21].copy()\n",
    "X_validation_csv = best_model[22].copy()\n",
    "\n",
    "X_train_csv[response_value] = best_model[18]\n",
    "X_validation_csv[response_value] = best_model[19]\n",
    "\n",
    "X_train_csv[f'Predicted {response_value}'] = best_model[11]\n",
    "X_validation_csv[f'Predicted {response_value}'] =  best_model[12]\n",
    " \n",
    "X_train_csv = pd.concat([X_train_csv, best_model[9]], axis=1)\n",
    "X_validation_csv = pd.concat([X_validation_csv, best_model[14]], axis=1)\n",
    "\n",
    "X_train_csv['Set'] = 'Training'\n",
    "X_validation_csv['Set'] = 'Validation'\n",
    "\n",
    "df_csv = pd.concat([X_train_csv, X_validation_csv], axis=0)\n",
    "\n",
    "#creates an Excel database with only the most important descriptors used by the model\n",
    "export_param_excel = df_csv.to_csv(f'Final_dataset/{csv_name}_final_dataset.csv', index = None, header=True)\n",
    "\n",
    "# Plot training and test sets\n",
    "if mode == 'reg':\n",
    "    sb.set(font_scale=1.2, style=\"ticks\") #set styling preferences\n",
    "\n",
    "    Plotdata_train_PFI = {'y_train_PFI': best_model[18], 'y_pred_train_PFI':  best_model[11]} \n",
    "    Plotdata_validation_PFI = {'y_validation_PFI': best_model[19], 'y_pred_validation_PFI':  best_model[12]}\n",
    "\n",
    "    df_train_PFI = pd.DataFrame.from_dict(Plotdata_train_PFI)\n",
    "    df_validation_PFI = pd.DataFrame.from_dict(Plotdata_validation_PFI)\n",
    "\n",
    "    # Build the plot\n",
    "    # Set up some features to plot the dots\n",
    "    color_train = 'b'\n",
    "    color_validation = 'orange'\n",
    "    size = 30\n",
    "    alpha = 1 # from 0 (transparent) to 1 (opaque)\n",
    "\n",
    "    # Create subplot with a certain size and title\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "    # Set styling preferences\n",
    "    sb.set(font_scale=1.2, style=\"ticks\")\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    # title of the graph\n",
    "    total_points = len(best_model[18])+len(best_model[19])\n",
    "    train_proportion = len(best_model[18])/total_points\n",
    "    validation_proportion = len(best_model[19])/total_points\n",
    "    ratios =  str(round(train_proportion,2)*100)+':'+str(round(validation_proportion,2)*100)\n",
    "    title_text = best_model[0]+' model with train:validation ('+ratios+') of '+str(total_points)+' datapoints'\n",
    "    \n",
    "    plt.text(0.5, 1.08, title_text, horizontalalignment='center',\n",
    "         fontsize=14, fontweight='bold', transform = ax.transAxes)\n",
    "\n",
    "    # Plot the data\n",
    "    points_train = ax.scatter(df_train_PFI[\"y_train_PFI\"], df_train_PFI[\"y_pred_train_PFI\"],\n",
    "                c = color_train, s = size, edgecolor = 'k', linewidths = 0.8, alpha = alpha, zorder=2)\n",
    "\n",
    "    points_validation = ax.scatter(df_validation_PFI[\"y_validation_PFI\"], df_validation_PFI[\"y_pred_validation_PFI\"],\n",
    "                c = color_validation, s = size, edgecolor = 'k', linewidths = 0.8, alpha = alpha, zorder=2)\n",
    "\n",
    "    # Put a legend below current axis\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.17),\n",
    "            fancybox=True, shadow=True, ncol=5, labels=['Training','Validation'])\n",
    "\n",
    "    # Add the regression line with a confidence interval based on the training sets\n",
    "    plot = sb.regplot(\"y_train_PFI\", \"y_pred_train_PFI\", data=df_train_PFI, scatter=False, color=\".1\", \n",
    "                    truncate = True, ax=ax)\n",
    "\n",
    "    # Title of the axis\n",
    "    plot = ax.set(ylabel=f'Predicted {response_value}', xlabel=f'{response_value} from database')\n",
    "    \n",
    "    # Add gridlines\n",
    "    ax.grid(linestyle='--', linewidth=1)\n",
    "\n",
    "    # set limits\n",
    "    size_space = 0.1*abs(min(best_model[18])-max(best_model[18]))\n",
    "    if min(best_model[18]) < min(best_model[19]):\n",
    "        min_value_graph = min(best_model[18])-size_space\n",
    "    else:\n",
    "        min_value_graph = min(best_model[19])-size_space\n",
    "        \n",
    "    if max(best_model[18]) > max(best_model[19]):\n",
    "        max_value_graph = max(best_model[18])+size_space\n",
    "    else:\n",
    "        max_value_graph = max(best_model[19])+size_space\n",
    "        \n",
    "    plt.xlim(min_value_graph, max_value_graph)\n",
    "    plt.ylim(min_value_graph, max_value_graph)\n",
    "        \n",
    "    # save the plot a png image, type True\n",
    "    plt.savefig('Predicted vs database values.png', dpi=400, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print('\\nThe corresponding graph was saved in '+w_dir+'.')\n",
    "\n",
    "elif mode == 'clas':\n",
    "    predictor_model = predictor_model_fun(best_model[0], best_model[1], seed, mode)\n",
    "\n",
    "    predictor_model.fit(best_model[9], best_model[18])\n",
    "\n",
    "    plot_confusion_matrix(predictor_model, best_model[14], best_model[19],cmap='Blues') \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results from the x-shuffle test\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'predictor_model_fun' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [49], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m     random\u001b[39m.\u001b[39mshuffle(row)\n\u001b[0;32m     54\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mResults from the x-shuffle test\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,y_pred_train_tests,y_pred_validation_tests \u001b[39m=\u001b[39m predictor_workflow(random_init,model_type,best_parameters_df,X_train_shuffled_scaled,y_train_tests,X_validation_shuffled_scaled,y_validation_tests,prediction_type,training_size)\n\u001b[0;32m     56\u001b[0m cv_score_x_shuffle \u001b[39m=\u001b[39m cross_val_calc(random_init,model_type,best_parameters_df,X_train_shuffled_scaled,y_train_tests,prediction_type,cv_kfold)\n\u001b[0;32m     57\u001b[0m print_model_stats(model_type,X_train_tests_scaled,X_validation_tests_scaled,r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,prediction_type,cv_score_x_shuffle,cv_kfold,\u001b[39m'\u001b[39m\u001b[39mRobert_results_x-shuffle.txt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\robert\\Robert_functions.py:622\u001b[0m, in \u001b[0;36mpredictor_workflow\u001b[1;34m(random_init_fun, model_type_fun, df_fun, X_train_scaled_fun, y_train_fun, X_validation_scaled_fun, y_validation_fun, prediction_type_fun, train_partition)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredictor_workflow\u001b[39m(random_init_fun,model_type_fun,df_fun,X_train_scaled_fun,y_train_fun,X_validation_scaled_fun,y_validation_fun,prediction_type_fun,train_partition):\n\u001b[0;32m    616\u001b[0m \n\u001b[0;32m    617\u001b[0m     \u001b[39m# just for simplicity and saving code lines, in classification:\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[39m# 1. r2 = accuracy classification score (proportion of correct predictions)\u001b[39;00m\n\u001b[0;32m    619\u001b[0m     \u001b[39m# 2. mae = F1 score (balanced F-score)\u001b[39;00m\n\u001b[0;32m    620\u001b[0m     \u001b[39m# 3. rmse = Matthews correlation coefficient (MCC)\u001b[39;00m\n\u001b[1;32m--> 622\u001b[0m     predictor_model \u001b[39m=\u001b[39m predictor_model_fun(model_type_fun, df_fun, random_init_fun, prediction_type_fun)\n\u001b[0;32m    624\u001b[0m     predictor_model\u001b[39m.\u001b[39mfit(X_train_scaled_fun, y_train_fun)\n\u001b[0;32m    626\u001b[0m     y_pred_train_fun \u001b[39m=\u001b[39m predictor_model\u001b[39m.\u001b[39mpredict(X_train_scaled_fun)\n",
      "File \u001b[1;32mc:\\Users\\David\\Desktop\\robert\\Robert_functions.py:789\u001b[0m, in \u001b[0;36mpredictor_model_fun\u001b[1;34m(model_type_fun, best_parameters_df, random_state, prediction_type_fun)\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMultivariate models (model_type = \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mMVL\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) are not compatible with classifiers (prediction_type = \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mclas\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    787\u001b[0m         sys\u001b[39m.\u001b[39mexit()\n\u001b[1;32m--> 789\u001b[0m \u001b[39mreturn\u001b[39;00m predictor_model_fun\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'predictor_model_fun' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# run x- and y-shuffle statistical tests\n",
    "random.seed(a=seed)\n",
    "\n",
    "# load original data\n",
    "df_tests_model = pd.read_csv(f'Final_dataset/{csv_name}_final_dataset.csv')\n",
    "\n",
    "training_data = df_tests_model[df_tests_model.Set == 'Training']\n",
    "validation_data = df_tests_model[df_tests_model.Set == 'Validation']\n",
    "\n",
    "# parameters to discard from the csv\n",
    "shuffle_drops = fixed_descriptors.copy()\n",
    "shuffle_drops.append('Set')\n",
    "shuffle_drops.append('Predicted '+response_value)\n",
    "\n",
    "X_train_tests = training_data.drop(shuffle_drops, axis=1)\n",
    "X_validation_tests = validation_data.drop(shuffle_drops, axis=1)\n",
    "\n",
    "y_train_tests = training_data[response_value]\n",
    "y_validation_tests = validation_data[response_value]\n",
    "\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean_tests = X_train_tests.mean(axis=0)\n",
    "Xstd_tests = X_train_tests.std(axis=0)\n",
    "X_train_tests_scaled = (X_train_tests - Xmean) / Xstd\n",
    "X_validation_tests_scaled = (X_validation_tests - Xmean) / Xstd\n",
    "\n",
    "y_train_tests = training_data[response_value]\n",
    "y_validation_tests = validation_data[response_value]\n",
    "\n",
    "# x shuffle test\n",
    "X_train_shuffled = training_data.drop(shuffle_drops, axis=1)\n",
    "X_validation_shuffled = validation_data.drop(shuffle_drops, axis=1)\n",
    "\n",
    "# fixed_descriptors\n",
    "X_train_shuffled = np.asarray(X_train_shuffled)\n",
    "X_validation_shuffled = np.asarray(X_validation_shuffled)\n",
    "\n",
    "# standardizes the data sets using the mean and standard dev from the train set\n",
    "Xmean = X_train_shuffled.mean(axis=0)\n",
    "Xstd = X_train_shuffled.std(axis=0)\n",
    "X_train_shuffled_scaled = (X_train_shuffled - Xmean) / Xstd\n",
    "X_validation_shuffled_scaled = (X_validation_shuffled - Xmean) / Xstd\n",
    "\n",
    "for row in X_train_shuffled_scaled:\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    \n",
    "for row in X_validation_shuffled_scaled:\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "    random.shuffle(row)\n",
    "\n",
    "print('\\nResults from the x-shuffle test')\n",
    "r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,y_pred_train_tests,y_pred_validation_tests = predictor_workflow(seed,model,best_parameters_df,X_train_shuffled_scaled,y_train_tests,X_validation_shuffled_scaled,y_validation_tests,mode,train)\n",
    "cv_score_x_shuffle = cross_val_calc(seed,model,best_parameters_df,X_train_shuffled_scaled,y_train_tests,mode,cv_kfold)\n",
    "print_model_stats(model,X_train_tests_scaled,X_validation_tests_scaled,r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,mode,cv_score_x_shuffle,cv_kfold,'Robert_results_x-shuffle.txt')\n",
    "\n",
    "# y shuffle test\n",
    "y_train_shuffled = y_train_tests.copy()\n",
    "y_validation_shuffled = y_validation_tests.copy()\n",
    "\n",
    "y_train_shuffled = np.asarray(y_train_shuffled)   \n",
    "y_validation_shuffled = np.asarray(y_validation_shuffled) \n",
    "\n",
    "random.shuffle(y_train_shuffled)\n",
    "random.shuffle(y_validation_shuffled)\n",
    "\n",
    "print('\\nResults from the y-shuffle test')\n",
    "r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,y_pred_train_tests,y_pred_validation_tests = predictor_workflow(seed,model,best_parameters_df,X_train_tests_scaled,y_train_shuffled,X_validation_tests_scaled,y_validation_shuffled,mode,train)\n",
    "cv_score_y_shuffle = cross_val_calc(seed,model,best_parameters_df,X_train_tests_scaled,y_train_shuffled,mode,cv_kfold)\n",
    "print_model_stats(model,X_train_tests_scaled,X_validation_tests_scaled,r2_train_tests,mae_train_tests,rmse_train_tests,r2_validation_tests,mae_validation_tests,rmse_validation_tests,mode,cv_score_y_shuffle,cv_kfold,'Robert_results_y-shuffle.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c100345108a7047ea96fae483cb64f49bdc23a8b225db90a5987a96959e820b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
